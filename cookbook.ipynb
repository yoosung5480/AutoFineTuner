{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "458ab4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AutoFineTuner.tool import codeLauncher\n",
    "from AutoFineTuner.tool import codeMaker\n",
    "from AutoFineTuner.tool import codeReader\n",
    "from AutoFineTuner.tool.paths import get_output_paths, get_proj_paths\n",
    "from AutoFineTuner.tool import json_tools\n",
    "from AutoFineTuner.tool import llms\n",
    "from AutoFineTuner.workflows.codeRepair.repair import repair_code\n",
    "from AutoFineTuner.workflows.codeRefactor.refactor import start_refactor\n",
    "from AutoFineTuner.workflows.finetuningManager.tuning_manager import start_finetuning\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e24ff5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "파일이 존재하지 않습니다: /home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/main.py",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 17\u001b[0m\n\u001b[1;32m     11\u001b[0m proj_paths \u001b[38;5;241m=\u001b[39m get_proj_paths(\n\u001b[1;32m     12\u001b[0m                             proj_root\u001b[38;5;241m=\u001b[39mproj_path, \n\u001b[1;32m     13\u001b[0m                             target\u001b[38;5;241m=\u001b[39mtarget_name, \n\u001b[1;32m     14\u001b[0m                             refactored\u001b[38;5;241m=\u001b[39mrefactored_name)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m## 필수 데이터\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m source_file_contents \u001b[38;5;241m=\u001b[39m \u001b[43mcodeReader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_text_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mproj_paths\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# refactored_code = codeReader.read_text_strict(str(proj_paths.refactored))\u001b[39;00m\n",
      "File \u001b[0;32m~/바탕화면/오픈소스경진대회/AutoFineTuner/AutoHPO/AutoFineTuner/tool/codeReader.py:16\u001b[0m, in \u001b[0;36mread_text_strict\u001b[0;34m(path_str)\u001b[0m\n\u001b[1;32m     14\u001b[0m p \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(path_str)\u001b[38;5;241m.\u001b[39mexpanduser()\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m p\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m파일이 존재하지 않습니다: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m p\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIsADirectoryError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m파일이 아니라 디렉터리/특수파일입니다: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: 파일이 존재하지 않습니다: /home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/main.py"
     ]
    }
   ],
   "source": [
    "proj_path = \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/\"    # params.txt, refactored.py 생성장소\n",
    "save_dir = \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/\"     # 훈련결과 저장장소\n",
    "target_name = \"main.py\"\n",
    "refactored_name = \"test_output.py\"                                                  # 리펙토링될 코드 생성이름  \n",
    "conda_env_name = \"AItxt\"                                                        # llm이 분석한 파라미터 내용\n",
    "max_steps=10\n",
    "userPrompt = \"이틀 내에 작업을 완료하고싶어. 데이터는 참고로 대략 10~20만개의 문장이 준비돼있어.\"\n",
    "\n",
    "\n",
    "output_paths = get_output_paths(save_dir=save_dir)\n",
    "proj_paths = get_proj_paths(\n",
    "                            proj_root=proj_path, \n",
    "                            target=target_name, \n",
    "                            refactored=refactored_name)\n",
    "\n",
    "## 필수 데이터\n",
    "source_file_contents = codeReader.read_text_strict(str(proj_paths.target))\n",
    "# refactored_code = codeReader.read_text_strict(str(proj_paths.refactored))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19770fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== modelReasoning 노드 실행 ======================\n",
      "### 1. **AI 라이브러리/모델 목적/훈련 흐름 분석**\n",
      "\n",
      "#### **라이브러리 및 모델**\n",
      "- **라이브러리**: \n",
      "  - `transformers` (HuggingFace): `RobertaForSequenceClassification`, `AutoTokenizer` 사용\n",
      "  - `torch`: 딥러닝 연산 및 모델 학습\n",
      "  - `sklearn`: 데이터 분할 (`train_test_split`)\n",
      "  - `pandas`, `numpy`: 데이터 처리\n",
      "- **모델**: \n",
      "  - **`klue/roberta-base`** (KoLRUE 기반 한국어 RoBERTa) + 2-class 분류 헤드 (`num_labels=2`).  \n",
      "  - 목적: 텍스트 분류 (이진 분류, 예: \"AI 작성 여부 판단\").\n",
      "\n",
      "#### **훈련 흐름**\n",
      "1. **데이터 로드**: \n",
      "   - `from_csv` 함수로 CSV에서 텍스트/레이블 로드 (`train.csv`).\n",
      "   - `BertDataset` 클래스로 토큰화 및 배치 생성.\n",
      "2. **모델 초기화**: \n",
      "   - 사전 학습된 RoBERTa 모델에 분류 레이어 추가.\n",
      "   - `AdamW` 옵티마이저 + 학습률 스케줄러 (`linear with warmup`) 적용.\n",
      "3. **학습 루프**:\n",
      "   - **훈련**: \n",
      "     - 배치 단위 학습, 크로스엔트로피 손실(`loss`) 계산 및 역전파.\n",
      "     - `flat_accuracy`로 정확도 평가.\n",
      "   - **검증**: \n",
      "     - 소프트맥스 적용 후 클래스별 확률 비교.\n",
      "4. **추론**: \n",
      "   - 테스트 데이터(`test.csv`)에 대해 `generated` 확률 예측 후 CSV 출력.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. **튜닝 후보 하이퍼파라미터**\n",
      "\n",
      "#### **(1) 학습률 (`lr`)**\n",
      "- **현재 값**: `5e-5` (라인 142).\n",
      "- **제안 범위**: `[2e-5, 3e-5, 5e-5, 1e-4]`.  \n",
      "  **근거**: BERT 계열 모델의 일반적인 학습률 범위이며, 논문에 따라 `2e-5`가 안정적.\n",
      "\n",
      "#### **(2) 배치 크기 (`batch_size`)**\n",
      "- **현재 값**: 훈련 `96` (라인 49), 테스트 `128` (라인 183).\n",
      "- **제안 값**: `[32, 64, 128]`.  \n",
      "  **근거**: GPU 메모리 한계 내에서 큰 배치는 학습 속도 향상, 작은 배치는 일반화 성능 개선.\n",
      "\n",
      "#### **(3) 에폭 수 (`epochs`)**\n",
      "- **현재 값**: `3` (라인 131).\n",
      "- **제안 값**: `[2, 4, 5]`.  \n",
      "  **근거**: 과적합 방지를 위해 조기 종료(Early Stopping) 도입과 함께 튜닝.\n",
      "\n",
      "#### **(4) 가중치 감소 (`weight_decay_rate`)**\n",
      "- **현재 값**: `0.1` (라인 121), `0.0` (레이어 정규화/바이어스 제외).\n",
      "- **제안 값**: `[0.01, 0.05, 0.1]`.  \n",
      "  **근거**: L2 정규화 강도로 과적합 제어.\n",
      "\n",
      "#### **(5) 최대 시퀀스 길이 (`max_len`)**\n",
      "- **현재 값**: `512` (라인 48).\n",
      "- **제안 값**: `[128, 256, 512]`.  \n",
      "  **근거**: 짧은 텍스트는 계산 비용 절감 가능.\n",
      "\n",
      "#### **(6) 드롭아웃 (`dropout`)**\n",
      "- **현재 값**: 모델 기본값 (RoBERTa: `0.1`).\n",
      "- **제안 값**: `[0.1, 0.2, 0.3]`.  \n",
      "  **근거**: 분류 헤드의 드롭아웃 레이어 추가 시 튜닝.\n",
      "\n",
      "#### **(7) 워밍업 스텝 (`num_warmup_steps`)**\n",
      "- **현재 값**: `0` (라인 152).\n",
      "- **제안 값**: `[100, 500, 1000]`.  \n",
      "  **근거**: 학습 초기 불안정성 완화.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. **추가 개선 방안**\n",
      "- **조기 종료**: 검증 손실이 개선되지 않을 때 학습 중단.\n",
      "- **데이터 증강**: 한국어 텍스트에 맞는 증강 기법 (예: 동의어 치환).\n",
      "- **모델 선택**: `klue/roberta-large`로 성능 비교.\n",
      "- **평가 지표**: 정확도 외 F1-score, AUC-ROC 추가.\n",
      "\n",
      "> **코드 위치 참고**:  \n",
      "> - 학습률: 라인 142  \n",
      "> - 배치 크기: 라인 49, 183  \n",
      "> - 에폭 수: 라인 131  \n",
      "> - 가중치 감소: 라인 121  \n",
      "> - 시퀀스 길이: 라인 48  \n",
      "> - 학습 스케줄링: 라인 152\n",
      "===================== searchHyperParam 노드 실행 ======================\n",
      "### **코드 분석 및 AI 모델 목적**\n",
      "1. **목적**:  \n",
      "   - **텍스트 분류 (Binary Classification)**: KLUE-RoBERTa 모델을 사용해 주어진 텍스트(문단)가 \"AI 생성\"인지 판별 (`num_labels=2`, `softmax(logits)` 활용).\n",
      "   - **데이터셋**: `train.csv`에서 학습, `test.csv`에서 추론 후 `submission.csv` 생성.\n",
      "\n",
      "2. **모델 훈련 흐름**:\n",
      "   - **모델**: `RobertaForSequenceClassification` (KLUE-RoBERTa-base).\n",
      "   - **토크나이저**: `AutoTokenizer.from_pretrained(\"klue/roberta-base\")`.\n",
      "   - **데이터 전처리**: `BertDataset` 클래스에서 토큰화 및 패딩 처리 (`max_len=512`).\n",
      "   - **학습 설정**:\n",
      "     - **옵티마이저**: AdamW (학습률 `5e-5`, weight decay 적용).\n",
      "     - **학습률 스케줄러**: `get_linear_schedule_with_warmup` (warmup 단계 없음).\n",
      "     - **평가 지표**: 검증 정확도 (`flat_accuracy`).\n",
      "\n",
      "3. **주요 코드 위치**:\n",
      "   - 모델 정의: `RobertaForSequenceClassification.from_pretrained(\"klue/roberta-base\", num_labels=2)`.\n",
      "   - 데이터 로드: `from_csv()` 함수 (라인 20), `BertDataset` 클래스 (라인 21-22).\n",
      "   - 학습 루프: `for _ in trange(epochs, desc=\"Epoch\")` (라인 60-80).\n",
      "   - 추론: `softmax(logits)` (라인 120), `submission.csv` 생성 (라인 130-133).\n",
      "\n",
      "---\n",
      "\n",
      "### **하이퍼파라미터 튜닝 후보**\n",
      "1. **학습률 (`lr`)**:\n",
      "   - **현재 값**: `5e-5` (라인 55).\n",
      "   - **후보 값**: `2e-5`, `3e-5`, `1e-4` (BERT 계열 모델의 일반적 범위).\n",
      "   - **근거**: 학습률은 모델 수렴 속도와 성능에 직접적 영향.\n",
      "\n",
      "2. **에폭 수 (`epochs`)**:\n",
      "   - **현재 값**: `3` (라인 45).\n",
      "   - **후보 값**: `2`, `4`, `5` (과적합 방지 및 데이터 크기 고려).\n",
      "\n",
      "3. **배치 크기 (`batch_size`)**:\n",
      "   - **현재 값**: 학습 `96`, 추론 `128` (라인 23, 108).\n",
      "   - **후보 값**: `32`, `64`, `128` (GPU 메모리 및 학습 안정성 고려).\n",
      "\n",
      "4. **Weight Decay**:\n",
      "   - **현재 값**: `0.1` (no_decay 파라미터 제외) (라인 48-53).\n",
      "   - **후보 값**: `0.01`, `0.05` (정규화 강도 조절).\n",
      "\n",
      "5. **시퀀스 길이 (`max_len`)**:\n",
      "   - **현재 값**: `512` (라인 23).\n",
      "   - **후보 값**: `256`, `384` (짧은 텍스트에서 계산 효율성 향상).\n",
      "\n",
      "6. **Warmup 단계**:\n",
      "   - **현재 값**: `0` (라인 58).\n",
      "   - **후보 값**: `total_steps * 0.1` (학습 초기 안정화).\n",
      "\n",
      "7. **모델 아키텍처**:\n",
      "   - **현재 모델**: `roberta-base`.\n",
      "   - **후보 모델**: `klue/roberta-large` (성능 향상 가능성).\n",
      "\n",
      "8. **드롭아웃 (Dropout)**:\n",
      "   - **현재 값**: RoBERTa 기본값.\n",
      "   - **후보 값**: `0.1` → `0.2` (과적합 감소).\n",
      "\n",
      "---\n",
      "\n",
      "### **추가 개선 방향**\n",
      "1. **데이터 증강**: 텍스트 변형 기법 적용 (예: 동의어 치환).\n",
      "2. **Early Stopping**: 검증 손실이 개선되지 않을 때 학습 조기 종료.\n",
      "3. **교차 검증**: `train_test_split` 비율 조정 (현재 검증 데이터 분할 코드 없음).\n",
      "4. **로그 분석**: `train_loss_set` 시각화 외에 검증 손실 추가 모니터링.\n",
      "\n",
      "> **코드 기반 근거**: 학습률/에폭/배치 크기는 BERT 파인튜닝의 표준 튜닝 파라미터이며, `run_glue.py` (라인 3-5)와 유사한 설정을 따름.\n",
      "===================== codeRefactoring 노드 실행 ======================\n",
      "import sys, json, time, pickle\n",
      "from pathlib import Path\n",
      "\n",
      "def _save_model_generic(model, path: Path) -> str:\n",
      "    \"\"\"Try torch save, else pickle; always write to *.pt\"\"\"\n",
      "    path.parent.mkdir(parents=True, exist_ok=True)\n",
      "    try:\n",
      "        import torch  # type: ignore\n",
      "        try:\n",
      "            torch.save(getattr(model, \"state_dict\", lambda: model)(), path)\n",
      "        except Exception:\n",
      "            torch.save(model, path)\n",
      "    except Exception:\n",
      "        with open(path, \"wb\") as f:\n",
      "            pickle.dump(model, f)\n",
      "    return str(path)\n",
      "\n",
      "def _emit_json_line(payload: dict) -> None:\n",
      "    sys.stdout.write(json.dumps(payload, ensure_ascii=False) + \"\\n\")\n",
      "    sys.stdout.flush()\n",
      "\n",
      "def _save_json_line(payload: dict) -> None:\n",
      "    # Alias to keep compatibility with pseudocode\n",
      "    _emit_json_line(payload)\n",
      "\n",
      "def autofinetuner_result() -> dict:\n",
      "    \"\"\"\n",
      "    Returns:\n",
      "      {\n",
      "        \"model_pt_path\": str,\n",
      "        \"validation\": float,\n",
      "        \"params\": dict\n",
      "      }\n",
      "    \"\"\"\n",
      "    import argparse\n",
      "    import pandas as pd\n",
      "    import numpy as np\n",
      "    import torch\n",
      "    from transformers import AutoTokenizer, RobertaForSequenceClassification, get_linear_schedule_with_warmup\n",
      "    from torch.optim import AdamW\n",
      "    from tqdm import trange\n",
      "    from dataset import BertDataset, from_csv\n",
      "\n",
      "    t0 = time.time()\n",
      "    parser = argparse.ArgumentParser()\n",
      "    parser.add_argument(\"--epochs\", type=int, default=1)\n",
      "    parser.add_argument(\"--batch_size\", type=int, default=1)\n",
      "    parser.add_argument(\"--save_dir\", type=str, default=\"./outputs\")\n",
      "    parser.add_argument(\"--train_path\", type=str, default=\"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv\")\n",
      "    parser.add_argument(\"--test_path\", type=str, default=\"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/test.csv\")\n",
      "    parser.add_argument(\"--healthcheck\", action=\"store_true\")\n",
      "    args, _ = parser.parse_known_args()\n",
      "\n",
      "    save_dir = Path(args.save_dir); save_dir.mkdir(parents=True, exist_ok=True)\n",
      "    model_path = save_dir / \"model.pt\"\n",
      "\n",
      "    # --- (1) 데이터 로드/전처리/모델 구성 ---\n",
      "    tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-base\")\n",
      "    model = RobertaForSequenceClassification.from_pretrained(\"klue/roberta-base\", num_labels=2)\n",
      "\n",
      "    train_texts, train_labels = from_csv(args.train_path)\n",
      "    dataset = BertDataset(train_texts, train_labels, tokenizer, max_len=512)\n",
      "    dataset.set_loaders(batch_size=max(1, int(args.batch_size)))\n",
      "    train_dataloader, valid_dataloader = dataset.get_loaders()\n",
      "\n",
      "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
      "    model.to(device)\n",
      "\n",
      "    if args.healthcheck:\n",
      "        try:\n",
      "            batch = next(iter(train_dataloader))\n",
      "        except StopIteration:\n",
      "            # 빈 데이터셋이면 임의의 더미 텐서로 forward\n",
      "            batch = (\n",
      "                torch.zeros((1, 4), dtype=torch.long),\n",
      "                torch.ones((1, 4), dtype=torch.long),\n",
      "                torch.zeros((1,), dtype=torch.long),\n",
      "            )\n",
      "        batch = tuple(t.to(device) for t in batch)\n",
      "        b_input_ids, b_input_mask, b_labels = batch\n",
      "        with torch.no_grad():\n",
      "            _ = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
      "        print(\"READY\")\n",
      "        raise SystemExit(0)\n",
      "\n",
      "    # --- Optimizer/Scheduler 구성 (원 코드 유지) ---\n",
      "    param_optimizer = list(model.named_parameters())\n",
      "    no_decay = ['bias', 'LayerNorm.weight']\n",
      "    optimizer_grouped_parameters = [\n",
      "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
      "         'weight_decay_rate': 0.1},\n",
      "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
      "         'weight_decay_rate': 0.0}\n",
      "    ]\n",
      "    optimizer = AdamW(optimizer_grouped_parameters, lr=5e-5, eps=1e-8)\n",
      "    total_steps = max(1, len(train_dataloader) * max(1, int(args.epochs)))\n",
      "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
      "\n",
      "    # Accuracy 계산 함수 (원 코드 유지)\n",
      "    def flat_accuracy(preds, labels):\n",
      "        pred_flat = np.argmax(preds, axis=1).flatten()\n",
      "        labels_flat = labels.flatten()\n",
      "        return float(np.sum(pred_flat == labels_flat) / len(labels_flat)) if len(labels_flat) > 0 else 0.0\n",
      "\n",
      "    train_loss_set = []\n",
      "    last_val_accuracy = 0.0\n",
      "\n",
      "    # --- (2) 학습 ---\n",
      "    for _ in trange(int(args.epochs), desc=\"Epoch\"):\n",
      "        model.train()\n",
      "        tr_loss = 0.0\n",
      "        nb_tr_steps = 0\n",
      "\n",
      "        for step, batch in enumerate(train_dataloader):\n",
      "            batch = tuple(t.to(device) for t in batch)\n",
      "            b_input_ids, b_input_mask, b_labels = batch\n",
      "            optimizer.zero_grad()\n",
      "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
      "            loss = outputs['loss'] if isinstance(outputs, dict) else outputs.loss\n",
      "            train_loss_set.append(loss.item())\n",
      "            loss.backward()\n",
      "            optimizer.step()\n",
      "            scheduler.step()\n",
      "\n",
      "            tr_loss += loss.item()\n",
      "            nb_tr_steps += 1\n",
      "\n",
      "        # Validation\n",
      "        model.eval()\n",
      "        eval_accuracy = 0.0\n",
      "        nb_eval_steps = 0\n",
      "\n",
      "        for batch in valid_dataloader:\n",
      "            batch = tuple(t.to(device) for t in batch)\n",
      "            b_input_ids, b_input_mask, b_labels = batch\n",
      "            with torch.no_grad():\n",
      "                outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
      "            logits = (outputs['logits'] if isinstance(outputs, dict) else outputs.logits).detach().cpu().numpy()\n",
      "            label_ids = b_labels.to('cpu').numpy()\n",
      "            tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
      "            eval_accuracy += tmp_eval_accuracy\n",
      "            nb_eval_steps += 1\n",
      "\n",
      "        last_val_accuracy = float(eval_accuracy / nb_eval_steps) if nb_eval_steps > 0 else 0.0\n",
      "\n",
      "    # --- 테스트 추론 및 제출 파일 생성 (원 코드 유지) ---\n",
      "    try:\n",
      "        if args.test_path and Path(args.test_path).exists():\n",
      "            test = pd.read_csv(args.test_path)\n",
      "            test_texts = test[\"paragraph_text\"].to_list()\n",
      "            labels = [0] * len(test_texts)\n",
      "            ids = test[\"ID\"].tolist()\n",
      "\n",
      "            infer_dataset = BertDataset(test_texts, labels, apply_preprocess=False, tokenizer=tokenizer)\n",
      "            infer_dataset.set_loaders(batch_size=max(1, int(args.batch_size)), split_ratio=1.0)\n",
      "            test_loader, _ = infer_dataset.get_loaders()\n",
      "\n",
      "            all_probs = []\n",
      "            model.eval()\n",
      "            for batch in test_loader:\n",
      "                input_ids, attn_mask, lbls = [t.to(device) for t in batch]\n",
      "                with torch.no_grad():\n",
      "                    outputs = model(input_ids, attention_mask=attn_mask)\n",
      "                    logits = (outputs['logits'] if isinstance(outputs, dict) else outputs.logits)\n",
      "                    probs = torch.softmax(logits, dim=-1)[:, 1]\n",
      "                    all_probs.extend(probs.cpu().numpy())\n",
      "\n",
      "            assert len(ids) == len(all_probs), f\"Mismatch: {len(ids)} IDs vs {len(all_probs)} predictions\"\n",
      "            submission = pd.DataFrame({\n",
      "                \"ID\": ids,\n",
      "                \"generated\": all_probs\n",
      "            })\n",
      "            submission.to_csv(\"submission.csv\", index=False)\n",
      "    except Exception as _e:\n",
      "        # Fail-safe: ignore inference errors to not block training result emission\n",
      "        pass\n",
      "\n",
      "    # --- (3) 모델 저장 ---\n",
      "    saved = _save_model_generic(model, model_path)\n",
      "\n",
      "    # --- (4) 결과 dict 구성 ---\n",
      "    used_params = {\n",
      "        \"epochs\": int(args.epochs),\n",
      "        \"batch_size\": int(args.batch_size),\n",
      "        \"train_path\": args.train_path,\n",
      "        \"test_path\": args.test_path,\n",
      "        \"model_name\": \"klue/roberta-base\",\n",
      "        \"lr\": 5e-5,\n",
      "        \"warmup_steps\": 0\n",
      "    }\n",
      "    val_metric = last_val_accuracy\n",
      "    result = {\n",
      "        \"model_pt_path\": saved,\n",
      "        \"validation\": float(val_metric),\n",
      "        \"params\": used_params\n",
      "    }\n",
      "\n",
      "    _save_json_line({\"autofinetuner_result\": result, \"elapsed_sec\": time.time() - t0})\n",
      "    with open(save_dir / \"save_dir.json\", \"w\", encoding=\"utf-8\") as f:\n",
      "        json.dump(result, f, ensure_ascii=False, indent=2)\n",
      "\n",
      "    return result\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    try:\n",
      "        _ = autofinetuner_result()\n",
      "    except SystemExit as _e:\n",
      "        if _e.code != 0:\n",
      "            raise\n",
      "===================== parseCode 노드 실행 ======================\n",
      "import sys, json, time, pickle\n",
      "from pathlib import Path\n",
      "\n",
      "def _save_model_generic(model, path: Path) -> str:\n",
      "    \"\"\"Try torch save, else pickle; always write to *.pt\"\"\"\n",
      "    path.parent.mkdir(parents=True, exist_ok=True)\n",
      "    try:\n",
      "        import torch  # type: ignore\n",
      "        try:\n",
      "            torch.save(getattr(model, \"state_dict\", lambda: model)(), path)\n",
      "        except Exception:\n",
      "            torch.save(model, path)\n",
      "    except Exception:\n",
      "        with open(path, \"wb\") as f:\n",
      "            pickle.dump(model, f)\n",
      "    return str(path)\n",
      "\n",
      "def _emit_json_line(payload: dict) -> None:\n",
      "    sys.stdout.write(json.dumps(payload, ensure_ascii=False) + \"\\n\")\n",
      "    sys.stdout.flush()\n",
      "\n",
      "def _save_json_line(payload: dict) -> None:\n",
      "    # Alias to keep compatibility with pseudocode\n",
      "    _emit_json_line(payload)\n",
      "\n",
      "def autofinetuner_result() -> dict:\n",
      "    \"\"\"\n",
      "    Returns:\n",
      "      {\n",
      "        \"model_pt_path\": str,\n",
      "        \"validation\": float,\n",
      "        \"params\": dict\n",
      "      }\n",
      "    \"\"\"\n",
      "    import argparse\n",
      "    import pandas as pd\n",
      "    import numpy as np\n",
      "    import torch\n",
      "    from transformers import AutoTokenizer, RobertaForSequenceClassification, get_linear_schedule_with_warmup\n",
      "    from torch.optim import AdamW\n",
      "    from tqdm import trange\n",
      "    from dataset import BertDataset, from_csv\n",
      "\n",
      "    t0 = time.time()\n",
      "    parser = argparse.ArgumentParser()\n",
      "    parser.add_argument(\"--epochs\", type=int, default=1)\n",
      "    parser.add_argument(\"--batch_size\", type=int, default=1)\n",
      "    parser.add_argument(\"--save_dir\", type=str, default=\"./outputs\")\n",
      "    parser.add_argument(\"--train_path\", type=str, default=\"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv\")\n",
      "    parser.add_argument(\"--test_path\", type=str, default=\"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/test.csv\")\n",
      "    parser.add_argument(\"--healthcheck\", action=\"store_true\")\n",
      "    args, _ = parser.parse_known_args()\n",
      "\n",
      "    save_dir = Path(args.save_dir); save_dir.mkdir(parents=True, exist_ok=True)\n",
      "    model_path = save_dir / \"model.pt\"\n",
      "\n",
      "    # --- (1) 데이터 로드/전처리/모델 구성 ---\n",
      "    tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-base\")\n",
      "    model = RobertaForSequenceClassification.from_pretrained(\"klue/roberta-base\", num_labels=2)\n",
      "\n",
      "    train_texts, train_labels = from_csv(args.train_path)\n",
      "    dataset = BertDataset(train_texts, train_labels, tokenizer, max_len=512)\n",
      "    dataset.set_loaders(batch_size=max(1, int(args.batch_size)))\n",
      "    train_dataloader, valid_dataloader = dataset.get_loaders()\n",
      "\n",
      "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
      "    model.to(device)\n",
      "\n",
      "    if args.healthcheck:\n",
      "        try:\n",
      "            batch = next(iter(train_dataloader))\n",
      "        except StopIteration:\n",
      "            # 빈 데이터셋이면 임의의 더미 텐서로 forward\n",
      "            batch = (\n",
      "                torch.zeros((1, 4), dtype=torch.long),\n",
      "                torch.ones((1, 4), dtype=torch.long),\n",
      "                torch.zeros((1,), dtype=torch.long),\n",
      "            )\n",
      "        batch = tuple(t.to(device) for t in batch)\n",
      "        b_input_ids, b_input_mask, b_labels = batch\n",
      "        with torch.no_grad():\n",
      "            _ = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
      "        print(\"READY\")\n",
      "        raise SystemExit(0)\n",
      "\n",
      "    # --- Optimizer/Scheduler 구성 (원 코드 유지) ---\n",
      "    param_optimizer = list(model.named_parameters())\n",
      "    no_decay = ['bias', 'LayerNorm.weight']\n",
      "    optimizer_grouped_parameters = [\n",
      "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
      "         'weight_decay_rate': 0.1},\n",
      "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
      "         'weight_decay_rate': 0.0}\n",
      "    ]\n",
      "    optimizer = AdamW(optimizer_grouped_parameters, lr=5e-5, eps=1e-8)\n",
      "    total_steps = max(1, len(train_dataloader) * max(1, int(args.epochs)))\n",
      "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
      "\n",
      "    # Accuracy 계산 함수 (원 코드 유지)\n",
      "    def flat_accuracy(preds, labels):\n",
      "        pred_flat = np.argmax(preds, axis=1).flatten()\n",
      "        labels_flat = labels.flatten()\n",
      "        return float(np.sum(pred_flat == labels_flat) / len(labels_flat)) if len(labels_flat) > 0 else 0.0\n",
      "\n",
      "    train_loss_set = []\n",
      "    last_val_accuracy = 0.0\n",
      "\n",
      "    # --- (2) 학습 ---\n",
      "    for _ in trange(int(args.epochs), desc=\"Epoch\"):\n",
      "        model.train()\n",
      "        tr_loss = 0.0\n",
      "        nb_tr_steps = 0\n",
      "\n",
      "        for step, batch in enumerate(train_dataloader):\n",
      "            batch = tuple(t.to(device) for t in batch)\n",
      "            b_input_ids, b_input_mask, b_labels = batch\n",
      "            optimizer.zero_grad()\n",
      "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
      "            loss = outputs['loss'] if isinstance(outputs, dict) else outputs.loss\n",
      "            train_loss_set.append(loss.item())\n",
      "            loss.backward()\n",
      "            optimizer.step()\n",
      "            scheduler.step()\n",
      "\n",
      "            tr_loss += loss.item()\n",
      "            nb_tr_steps += 1\n",
      "\n",
      "        # Validation\n",
      "        model.eval()\n",
      "        eval_accuracy = 0.0\n",
      "        nb_eval_steps = 0\n",
      "\n",
      "        for batch in valid_dataloader:\n",
      "            batch = tuple(t.to(device) for t in batch)\n",
      "            b_input_ids, b_input_mask, b_labels = batch\n",
      "            with torch.no_grad():\n",
      "                outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
      "            logits = (outputs['logits'] if isinstance(outputs, dict) else outputs.logits).detach().cpu().numpy()\n",
      "            label_ids = b_labels.to('cpu').numpy()\n",
      "            tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
      "            eval_accuracy += tmp_eval_accuracy\n",
      "            nb_eval_steps += 1\n",
      "\n",
      "        last_val_accuracy = float(eval_accuracy / nb_eval_steps) if nb_eval_steps > 0 else 0.0\n",
      "\n",
      "    # --- 테스트 추론 및 제출 파일 생성 (원 코드 유지) ---\n",
      "    try:\n",
      "        if args.test_path and Path(args.test_path).exists():\n",
      "            test = pd.read_csv(args.test_path)\n",
      "            test_texts = test[\"paragraph_text\"].to_list()\n",
      "            labels = [0] * len(test_texts)\n",
      "            ids = test[\"ID\"].tolist()\n",
      "\n",
      "            infer_dataset = BertDataset(test_texts, labels, apply_preprocess=False, tokenizer=tokenizer)\n",
      "            infer_dataset.set_loaders(batch_size=max(1, int(args.batch_size)), split_ratio=1.0)\n",
      "            test_loader, _ = infer_dataset.get_loaders()\n",
      "\n",
      "            all_probs = []\n",
      "            model.eval()\n",
      "            for batch in test_loader:\n",
      "                input_ids, attn_mask, lbls = [t.to(device) for t in batch]\n",
      "                with torch.no_grad():\n",
      "                    outputs = model(input_ids, attention_mask=attn_mask)\n",
      "                    logits = (outputs['logits'] if isinstance(outputs, dict) else outputs.logits)\n",
      "                    probs = torch.softmax(logits, dim=-1)[:, 1]\n",
      "                    all_probs.extend(probs.cpu().numpy())\n",
      "\n",
      "            assert len(ids) == len(all_probs), f\"Mismatch: {len(ids)} IDs vs {len(all_probs)} predictions\"\n",
      "            submission = pd.DataFrame({\n",
      "                \"ID\": ids,\n",
      "                \"generated\": all_probs\n",
      "            })\n",
      "            submission.to_csv(\"submission.csv\", index=False)\n",
      "    except Exception as _e:\n",
      "        # Fail-safe: ignore inference errors to not block training result emission\n",
      "        pass\n",
      "\n",
      "    # --- (3) 모델 저장 ---\n",
      "    saved = _save_model_generic(model, model_path)\n",
      "\n",
      "    # --- (4) 결과 dict 구성 ---\n",
      "    used_params = {\n",
      "        \"epochs\": int(args.epochs),\n",
      "        \"batch_size\": int(args.batch_size),\n",
      "        \"train_path\": args.train_path,\n",
      "        \"test_path\": args.test_path,\n",
      "        \"model_name\": \"klue/roberta-base\",\n",
      "        \"lr\": 5e-5,\n",
      "        \"warmup_steps\": 0\n",
      "    }\n",
      "    val_metric = last_val_accuracy\n",
      "    result = {\n",
      "        \"model_pt_path\": saved,\n",
      "        \"validation\": float(val_metric),\n",
      "        \"params\": used_params\n",
      "    }\n",
      "\n",
      "    _save_json_line({\"autofinetuner_result\": result, \"elapsed_sec\": time.time() - t0})\n",
      "    with open(save_dir / \"save_dir.json\", \"w\", encoding=\"utf-8\") as f:\n",
      "        json.dump(result, f, ensure_ascii=False, indent=2)\n",
      "\n",
      "    return result\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    try:\n",
      "        _ = autofinetuner_result()\n",
      "    except SystemExit as _e:\n",
      "        if _e.code != 0:\n",
      "            raise\n",
      "import sys, json, time, pickle\n",
      "from pathlib import Path\n",
      "\n",
      "def _save_model_generic(model, path: Path) -> str:\n",
      "    \"\"\"Try torch save, else pickle; always write to *.pt\"\"\"\n",
      "    path.parent.mkdir(parents=True, exist_ok=True)\n",
      "    try:\n",
      "        import torch  # type: ignore\n",
      "        try:\n",
      "            torch.save(getattr(model, \"state_dict\", lambda: model)(), path)\n",
      "        except Exception:\n",
      "            torch.save(model, path)\n",
      "    except Exception:\n",
      "        with open(path, \"wb\") as f:\n",
      "            pickle.dump(model, f)\n",
      "    return str(path)\n",
      "\n",
      "def _emit_json_line(payload: dict) -> None:\n",
      "    sys.stdout.write(json.dumps(payload, ensure_ascii=False) + \"\\n\")\n",
      "    sys.stdout.flush()\n",
      "\n",
      "def _save_json_line(payload: dict) -> None:\n",
      "    # Alias to keep compatibility with pseudocode\n",
      "    _emit_json_line(payload)\n",
      "\n",
      "def autofinetuner_result() -> dict:\n",
      "    \"\"\"\n",
      "    Returns:\n",
      "      {\n",
      "        \"model_pt_path\": str,\n",
      "        \"validation\": float,\n",
      "        \"params\": dict\n",
      "      }\n",
      "    \"\"\"\n",
      "    import argparse\n",
      "    import pandas as pd\n",
      "    import numpy as np\n",
      "    import torch\n",
      "    from transformers import AutoTokenizer, RobertaForSequenceClassification, get_linear_schedule_with_warmup\n",
      "    from torch.optim import AdamW\n",
      "    from tqdm import trange\n",
      "    from dataset import BertDataset, from_csv\n",
      "\n",
      "    t0 = time.time()\n",
      "    parser = argparse.ArgumentParser()\n",
      "    parser.add_argument(\"--epochs\", type=int, default=1)\n",
      "    parser.add_argument(\"--batch_size\", type=int, default=1)\n",
      "    parser.add_argument(\"--save_dir\", type=str, default=\"./outputs\")\n",
      "    parser.add_argument(\"--train_path\", type=str, default=\"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv\")\n",
      "    parser.add_argument(\"--test_path\", type=str, default=\"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/test.csv\")\n",
      "    parser.add_argument(\"--healthcheck\", action=\"store_true\")\n",
      "    args, _ = parser.parse_known_args()\n",
      "\n",
      "    save_dir = Path(args.save_dir); save_dir.mkdir(parents=True, exist_ok=True)\n",
      "    model_path = save_dir / \"model.pt\"\n",
      "\n",
      "    # --- (1) 데이터 로드/전처리/모델 구성 ---\n",
      "    tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-base\")\n",
      "    model = RobertaForSequenceClassification.from_pretrained(\"klue/roberta-base\", num_labels=2)\n",
      "\n",
      "    train_texts, train_labels = from_csv(args.train_path)\n",
      "    dataset = BertDataset(train_texts, train_labels, tokenizer, max_len=512)\n",
      "    dataset.set_loaders(batch_size=max(1, int(args.batch_size)))\n",
      "    train_dataloader, valid_dataloader = dataset.get_loaders()\n",
      "\n",
      "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
      "    model.to(device)\n",
      "\n",
      "    if args.healthcheck:\n",
      "        try:\n",
      "            batch = next(iter(train_dataloader))\n",
      "        except StopIteration:\n",
      "            # 빈 데이터셋이면 임의의 더미 텐서로 forward\n",
      "            batch = (\n",
      "                torch.zeros((1, 4), dtype=torch.long),\n",
      "                torch.ones((1, 4), dtype=torch.long),\n",
      "                torch.zeros((1,), dtype=torch.long),\n",
      "            )\n",
      "        batch = tuple(t.to(device) for t in batch)\n",
      "        b_input_ids, b_input_mask, b_labels = batch\n",
      "        with torch.no_grad():\n",
      "            _ = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
      "        print(\"READY\")\n",
      "        raise SystemExit(0)\n",
      "\n",
      "    # --- Optimizer/Scheduler 구성 (원 코드 유지) ---\n",
      "    param_optimizer = list(model.named_parameters())\n",
      "    no_decay = ['bias', 'LayerNorm.weight']\n",
      "    optimizer_grouped_parameters = [\n",
      "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
      "         'weight_decay_rate': 0.1},\n",
      "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
      "         'weight_decay_rate': 0.0}\n",
      "    ]\n",
      "    optimizer = AdamW(optimizer_grouped_parameters, lr=5e-5, eps=1e-8)\n",
      "    total_steps = max(1, len(train_dataloader) * max(1, int(args.epochs)))\n",
      "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
      "\n",
      "    # Accuracy 계산 함수 (원 코드 유지)\n",
      "    def flat_accuracy(preds, labels):\n",
      "        pred_flat = np.argmax(preds, axis=1).flatten()\n",
      "        labels_flat = labels.flatten()\n",
      "        return float(np.sum(pred_flat == labels_flat) / len(labels_flat)) if len(labels_flat) > 0 else 0.0\n",
      "\n",
      "    train_loss_set = []\n",
      "    last_val_accuracy = 0.0\n",
      "\n",
      "    # --- (2) 학습 ---\n",
      "    for _ in trange(int(args.epochs), desc=\"Epoch\"):\n",
      "        model.train()\n",
      "        tr_loss = 0.0\n",
      "        nb_tr_steps = 0\n",
      "\n",
      "        for step, batch in enumerate(train_dataloader):\n",
      "            batch = tuple(t.to(device) for t in batch)\n",
      "            b_input_ids, b_input_mask, b_labels = batch\n",
      "            optimizer.zero_grad()\n",
      "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
      "            loss = outputs['loss'] if isinstance(outputs, dict) else outputs.loss\n",
      "            train_loss_set.append(loss.item())\n",
      "            loss.backward()\n",
      "            optimizer.step()\n",
      "            scheduler.step()\n",
      "\n",
      "            tr_loss += loss.item()\n",
      "            nb_tr_steps += 1\n",
      "\n",
      "        # Validation\n",
      "        model.eval()\n",
      "        eval_accuracy = 0.0\n",
      "        nb_eval_steps = 0\n",
      "\n",
      "        for batch in valid_dataloader:\n",
      "            batch = tuple(t.to(device) for t in batch)\n",
      "            b_input_ids, b_input_mask, b_labels = batch\n",
      "            with torch.no_grad():\n",
      "                outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
      "            logits = (outputs['logits'] if isinstance(outputs, dict) else outputs.logits).detach().cpu().numpy()\n",
      "            label_ids = b_labels.to('cpu').numpy()\n",
      "            tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
      "            eval_accuracy += tmp_eval_accuracy\n",
      "            nb_eval_steps += 1\n",
      "\n",
      "        last_val_accuracy = float(eval_accuracy / nb_eval_steps) if nb_eval_steps > 0 else 0.0\n",
      "\n",
      "    # --- 테스트 추론 및 제출 파일 생성 (원 코드 유지) ---\n",
      "    try:\n",
      "        if args.test_path and Path(args.test_path).exists():\n",
      "            test = pd.read_csv(args.test_path)\n",
      "            test_texts = test[\"paragraph_text\"].to_list()\n",
      "            labels = [0] * len(test_texts)\n",
      "            ids = test[\"ID\"].tolist()\n",
      "\n",
      "            infer_dataset = BertDataset(test_texts, labels, apply_preprocess=False, tokenizer=tokenizer)\n",
      "            infer_dataset.set_loaders(batch_size=max(1, int(args.batch_size)), split_ratio=1.0)\n",
      "            test_loader, _ = infer_dataset.get_loaders()\n",
      "\n",
      "            all_probs = []\n",
      "            model.eval()\n",
      "            for batch in test_loader:\n",
      "                input_ids, attn_mask, lbls = [t.to(device) for t in batch]\n",
      "                with torch.no_grad():\n",
      "                    outputs = model(input_ids, attention_mask=attn_mask)\n",
      "                    logits = (outputs['logits'] if isinstance(outputs, dict) else outputs.logits)\n",
      "                    probs = torch.softmax(logits, dim=-1)[:, 1]\n",
      "                    all_probs.extend(probs.cpu().numpy())\n",
      "\n",
      "            assert len(ids) == len(all_probs), f\"Mismatch: {len(ids)} IDs vs {len(all_probs)} predictions\"\n",
      "            submission = pd.DataFrame({\n",
      "                \"ID\": ids,\n",
      "                \"generated\": all_probs\n",
      "            })\n",
      "            submission.to_csv(\"submission.csv\", index=False)\n",
      "    except Exception as _e:\n",
      "        # Fail-safe: ignore inference errors to not block training result emission\n",
      "        pass\n",
      "\n",
      "    # --- (3) 모델 저장 ---\n",
      "    saved = _save_model_generic(model, model_path)\n",
      "\n",
      "    # --- (4) 결과 dict 구성 ---\n",
      "    used_params = {\n",
      "        \"epochs\": int(args.epochs),\n",
      "        \"batch_size\": int(args.batch_size),\n",
      "        \"train_path\": args.train_path,\n",
      "        \"test_path\": args.test_path,\n",
      "        \"model_name\": \"klue/roberta-base\",\n",
      "        \"lr\": 5e-5,\n",
      "        \"warmup_steps\": 0\n",
      "    }\n",
      "    val_metric = last_val_accuracy\n",
      "    result = {\n",
      "        \"model_pt_path\": saved,\n",
      "        \"validation\": float(val_metric),\n",
      "        \"params\": used_params\n",
      "    }\n",
      "\n",
      "    _save_json_line({\"autofinetuner_result\": result, \"elapsed_sec\": time.time() - t0})\n",
      "    with open(save_dir / \"save_dir.json\", \"w\", encoding=\"utf-8\") as f:\n",
      "        json.dump(result, f, ensure_ascii=False, indent=2)\n",
      "\n",
      "    return result\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    try:\n",
      "        _ = autofinetuner_result()\n",
      "    except SystemExit as _e:\n",
      "        if _e.code != 0:\n",
      "            raise\n"
     ]
    }
   ],
   "source": [
    "refactored_code = start_refactor(\n",
    "    source_code_contents=source_file_contents,\n",
    "    user_prompt=userPrompt\n",
    ")\n",
    "print(refactored_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9709007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeMaker.write_text_atomic(\n",
    "    path_str= proj_paths.refactored,\n",
    "    content = refactored_code \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec311884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실행 명령어 상태 :  ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--healthcheck']\n",
      "ion 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "2025-08-20 15:57:31.944362: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "READY\n",
      "\n",
      "===============================excuteCode result===============================\n",
      "{'ok': True, 'run_id': '20250820155727', 'returncode': 0, 'run_dir': 'outputs/20250820155727', 'log_path': 'outputs/20250820155727/run.log', 'cmd': ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--healthcheck'], 'error': None}\n",
      "===============================route_after_exec===============================\n",
      "코드 실행 성공!\n",
      "워크플로우 종료.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sourceCode': 'from transformers import AutoModel, AutoTokenizer\\n\\nimport torch\\nimport torch.nn as nn\\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\\nfrom keras.utils import pad_sequences\\nfrom sklearn.model_selection import train_test_split\\nfrom transformers import BertTokenizer, BertConfig\\nfrom transformers import BertForSequenceClassification, get_linear_schedule_with_warmup\\nfrom torch.optim import AdamW\\nfrom tqdm import tqdm, trange  #for progress bars\\nimport pandas as pd\\nimport io\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom IPython.display import Image #for image rendering\\n\\n\\nfrom dataset import BertDataset\\nfrom dataset import from_csv\\n\\n\\nfrom transformers import RobertaForSequenceClassification\\n\\nmodel = RobertaForSequenceClassification.from_pretrained(\\n    \"klue/roberta-base\",\\n    num_labels=2\\n)\\ntokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-base\")\\n\\ntrain_texts, train_labels = from_csv(\"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv\")\\ntest_dataset = BertDataset(train_texts, train_labels, tokenizer, max_len=512)\\ntest_dataset.set_loaders(batch_size=96)\\ntrain_dataloader, valid_dataloader = test_dataset.get_loaders()\\n\\nmodel.config\\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\nmodel.to(device)\\n#This code is taken from:\\n# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L102\\n\\n# Don\\'t apply weight decay to any parameters whose names include these tokens.\\n# (Here, the BERT doesn\\'t have `gamma` or `beta` parameters, only `bias` terms)\\nparam_optimizer = list(model.named_parameters())\\nno_decay = [\\'bias\\', \\'LayerNorm.weight\\']\\n# Separate the `weight` parameters from the `bias` parameters.\\n# - For the `weight` parameters, this specifies a \\'weight_decay_rate\\' of 0.01.\\n# - For the `bias` parameters, the \\'weight_decay_rate\\' is 0.0.\\noptimizer_grouped_parameters = [\\n    # Filter for all parameters which *don\\'t* include \\'bias\\', \\'gamma\\', \\'beta\\'.\\n    {\\'params\\': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\\n     \\'weight_decay_rate\\': 0.1},\\n\\n    # Filter for parameters which *do* include those.\\n    {\\'params\\': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\\n     \\'weight_decay_rate\\': 0.0}\\n]\\n# Note - `optimizer_grouped_parameters` only includes the parameter values, not\\n# the names.\\n\\n# optimizer = BertAdam(optimizer_grouped_parameters,\\n#                      lr=2e-5,\\n#                      warmup=.1)\\n\\n# Number of training epochs (authors recommend between 2 and 4)\\nepochs = 3\\n\\noptimizer = AdamW(optimizer_grouped_parameters,\\n                  lr = 5e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\\n                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\\n                  )\\n# Total number of training steps is number of batches * number of epochs.\\n# `train_dataloader` contains batched data so `len(train_dataloader)` gives\\n# us the number of batches.\\ntotal_steps = len(train_dataloader) * epochs\\n\\n# Create the learning rate scheduler.\\nscheduler = get_linear_schedule_with_warmup(optimizer,\\n                                            num_warmup_steps = 0, # Default value in run_glue.py\\n                                            num_training_steps = total_steps)\\n\\n#Creating the Accuracy Measurement Function\\n# Function to calculate the accuracy of our predictions vs labels\\ndef flat_accuracy(preds, labels):\\n    pred_flat = np.argmax(preds, axis=1).flatten()\\n    labels_flat = labels.flatten()\\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)\\n\\nt = []\\n\\n# Store our loss and accuracy for plotting\\ntrain_loss_set = []\\n\\n# trange is a tqdm wrapper around the normal python range\\nfor _ in trange(epochs, desc=\"Epoch\"):\\n\\n  # Training\\n\\n  # Set our model to training mode (as opposed to evaluation mode)\\n  model.train()\\n\\n  # Tracking variables\\n  tr_loss = 0\\n  nb_tr_examples, nb_tr_steps = 0, 0\\n\\n  # Train the data for one epoch\\n  for step, batch in enumerate(train_dataloader):\\n    # Add batch to GPU\\n    batch = tuple(t.to(device) for t in batch)\\n    # Unpack the inputs from our dataloader\\n    b_input_ids, b_input_mask, b_labels = batch\\n    # Clear out the gradients (by default they accumulate)\\n    optimizer.zero_grad()\\n    # Forward pass\\n    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\\n    loss = outputs[\\'loss\\']\\n    train_loss_set.append(loss.item())\\n    # Backward pass\\n    loss.backward()\\n    # Update parameters and take a step using the computed gradient\\n    optimizer.step()\\n\\n    # Update the learning rate.\\n    scheduler.step()\\n\\n\\n    # Update tracking variables\\n    tr_loss += loss.item()\\n    nb_tr_examples += b_input_ids.size(0)\\n    nb_tr_steps += 1\\n\\n  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\\n\\n  # Validation\\n\\n  # Put model in evaluation mode to evaluate loss on the validation set\\n  model.eval()\\n\\n  # Tracking variables\\n  eval_loss, eval_accuracy = 0, 0\\n  nb_eval_steps, nb_eval_examples = 0, 0\\n\\n  # Evaluate data for one epoch\\n  for batch in valid_dataloader:\\n    # Add batch to GPU\\n    batch = tuple(t.to(device) for t in batch)\\n    # Unpack the inputs from our dataloader\\n    b_input_ids, b_input_mask, b_labels = batch\\n    # Telling the model not to compute or store gradients, saving memory and speeding up validation\\n    with torch.no_grad():\\n      # Forward pass, calculate logit predictions\\n      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\\n\\n    # Move logits and labels to CPU\\n    logits = logits[\\'logits\\'].detach().cpu().numpy()\\n    label_ids = b_labels.to(\\'cpu\\').numpy()\\n\\n    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\\n\\n    eval_accuracy += tmp_eval_accuracy\\n    nb_eval_steps += 1\\n\\n  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\\n\\ntest = pd.read_csv(\"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/test.csv\")\\ntest_texts = test[\"paragraph_text\"].to_list()\\nlabels = [0]*len(test_texts)\\nids = test[\"ID\"].tolist()\\n\\ntokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-base\")\\ndataset = BertDataset(test_texts, labels, apply_preprocess=False, tokenizer=tokenizer)\\ndataset.set_loaders(batch_size=128, split_ratio=1.0)\\ntest_loader, _ = dataset.get_loaders()\\n\\nfor batch in test_loader:\\n    input_ids, attn_mask, labels = batch\\n    print(input_ids.shape, attn_mask.shape, labels.shape)\\n\\n#Softmax logits\\ndef softmax(logits):\\n    e = np.exp(logits)\\n    return e / np.sum(e)\\n\\n\\nall_probs = []\\n\\nmodel.eval()\\nfor batch in test_loader:\\n    input_ids, attn_mask, labels = [t.to(device) for t in batch]\\n\\n    with torch.no_grad():\\n        outputs = model(input_ids, attention_mask=attn_mask)\\n        logits = outputs.logits\\n        probs = torch.softmax(logits, dim=-1)[:, 1]  # ← \"AI가 썼을 확률\"\\n        all_probs.extend(probs.cpu().numpy())\\n\\n\\n# 예측 결과 수와 ID 수가 같아야 함\\nassert len(ids) == len(all_probs), f\"Mismatch: {len(ids)} IDs vs {len(all_probs)} predictions\"\\n\\n# 제출 파일 생성\\nsubmission = pd.DataFrame({\\n    \"ID\": ids,\\n    \"generated\": all_probs\\n})\\nsubmission.to_csv(\"submission.csv\", index=False)\\nprint(\"✅ submission.csv 저장 완료\")\\nplt.figure(figsize=(15,8))\\nplt.title(\"Training loss\")\\nplt.xlabel(\"Batch\")\\nplt.ylabel(\"Loss\")\\nplt.plot(train_loss_set)\\nplt.show()\\n\\n\\n# CUDA_VISIBLE_DEVICES=0 python main.py',\n",
       " 'refactoredCode': 'import sys, json, time, pickle\\nfrom pathlib import Path\\n\\ndef _save_model_generic(model, path: Path) -> str:\\n    \"\"\"Try torch save, else pickle; always write to *.pt\"\"\"\\n    path.parent.mkdir(parents=True, exist_ok=True)\\n    try:\\n        import torch  # type: ignore\\n        try:\\n            torch.save(getattr(model, \"state_dict\", lambda: model)(), path)\\n        except Exception:\\n            torch.save(model, path)\\n    except Exception:\\n        with open(path, \"wb\") as f:\\n            pickle.dump(model, f)\\n    return str(path)\\n\\ndef _emit_json_line(payload: dict) -> None:\\n    sys.stdout.write(json.dumps(payload, ensure_ascii=False) + \"\\\\n\")\\n    sys.stdout.flush()\\n\\ndef _save_json_line(payload: dict) -> None:\\n    # Alias to keep compatibility with pseudocode\\n    _emit_json_line(payload)\\n\\ndef autofinetuner_result() -> dict:\\n    \"\"\"\\n    Returns:\\n      {\\n        \"model_pt_path\": str,\\n        \"validation\": float,\\n        \"params\": dict\\n      }\\n    \"\"\"\\n    import argparse\\n    import pandas as pd\\n    import numpy as np\\n    import torch\\n    from transformers import AutoTokenizer, RobertaForSequenceClassification, get_linear_schedule_with_warmup\\n    from torch.optim import AdamW\\n    from tqdm import trange\\n    from dataset import BertDataset, from_csv\\n\\n    t0 = time.time()\\n    parser = argparse.ArgumentParser()\\n    parser.add_argument(\"--epochs\", type=int, default=1)\\n    parser.add_argument(\"--batch_size\", type=int, default=1)\\n    parser.add_argument(\"--save_dir\", type=str, default=\"./outputs\")\\n    parser.add_argument(\"--train_path\", type=str, default=\"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv\")\\n    parser.add_argument(\"--test_path\", type=str, default=\"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/test.csv\")\\n    parser.add_argument(\"--healthcheck\", action=\"store_true\")\\n    args, _ = parser.parse_known_args()\\n\\n    save_dir = Path(args.save_dir); save_dir.mkdir(parents=True, exist_ok=True)\\n    model_path = save_dir / \"model.pt\"\\n\\n    # --- (1) 데이터 로드/전처리/모델 구성 ---\\n    tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-base\")\\n    model = RobertaForSequenceClassification.from_pretrained(\"klue/roberta-base\", num_labels=2)\\n\\n    train_texts, train_labels = from_csv(args.train_path)\\n    dataset = BertDataset(train_texts, train_labels, tokenizer, max_len=512)\\n    dataset.set_loaders(batch_size=max(1, int(args.batch_size)))\\n    train_dataloader, valid_dataloader = dataset.get_loaders()\\n\\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n    model.to(device)\\n\\n    if args.healthcheck:\\n        try:\\n            batch = next(iter(train_dataloader))\\n        except StopIteration:\\n            # 빈 데이터셋이면 임의의 더미 텐서로 forward\\n            batch = (\\n                torch.zeros((1, 4), dtype=torch.long),\\n                torch.ones((1, 4), dtype=torch.long),\\n                torch.zeros((1,), dtype=torch.long),\\n            )\\n        batch = tuple(t.to(device) for t in batch)\\n        b_input_ids, b_input_mask, b_labels = batch\\n        with torch.no_grad():\\n            _ = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\\n        print(\"READY\")\\n        raise SystemExit(0)\\n\\n    # --- Optimizer/Scheduler 구성 (원 코드 유지) ---\\n    param_optimizer = list(model.named_parameters())\\n    no_decay = [\\'bias\\', \\'LayerNorm.weight\\']\\n    optimizer_grouped_parameters = [\\n        {\\'params\\': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\\n         \\'weight_decay_rate\\': 0.1},\\n        {\\'params\\': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\\n         \\'weight_decay_rate\\': 0.0}\\n    ]\\n    optimizer = AdamW(optimizer_grouped_parameters, lr=5e-5, eps=1e-8)\\n    total_steps = max(1, len(train_dataloader) * max(1, int(args.epochs)))\\n    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\\n\\n    # Accuracy 계산 함수 (원 코드 유지)\\n    def flat_accuracy(preds, labels):\\n        pred_flat = np.argmax(preds, axis=1).flatten()\\n        labels_flat = labels.flatten()\\n        return float(np.sum(pred_flat == labels_flat) / len(labels_flat)) if len(labels_flat) > 0 else 0.0\\n\\n    train_loss_set = []\\n    last_val_accuracy = 0.0\\n\\n    # --- (2) 학습 ---\\n    for _ in trange(int(args.epochs), desc=\"Epoch\"):\\n        model.train()\\n        tr_loss = 0.0\\n        nb_tr_steps = 0\\n\\n        for step, batch in enumerate(train_dataloader):\\n            batch = tuple(t.to(device) for t in batch)\\n            b_input_ids, b_input_mask, b_labels = batch\\n            optimizer.zero_grad()\\n            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\\n            loss = outputs[\\'loss\\'] if isinstance(outputs, dict) else outputs.loss\\n            train_loss_set.append(loss.item())\\n            loss.backward()\\n            optimizer.step()\\n            scheduler.step()\\n\\n            tr_loss += loss.item()\\n            nb_tr_steps += 1\\n\\n        # Validation\\n        model.eval()\\n        eval_accuracy = 0.0\\n        nb_eval_steps = 0\\n\\n        for batch in valid_dataloader:\\n            batch = tuple(t.to(device) for t in batch)\\n            b_input_ids, b_input_mask, b_labels = batch\\n            with torch.no_grad():\\n                outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\\n            logits = (outputs[\\'logits\\'] if isinstance(outputs, dict) else outputs.logits).detach().cpu().numpy()\\n            label_ids = b_labels.to(\\'cpu\\').numpy()\\n            tmp_eval_accuracy = flat_accuracy(logits, label_ids)\\n            eval_accuracy += tmp_eval_accuracy\\n            nb_eval_steps += 1\\n\\n        last_val_accuracy = float(eval_accuracy / nb_eval_steps) if nb_eval_steps > 0 else 0.0\\n\\n    # --- 테스트 추론 및 제출 파일 생성 (원 코드 유지) ---\\n    try:\\n        if args.test_path and Path(args.test_path).exists():\\n            test = pd.read_csv(args.test_path)\\n            test_texts = test[\"paragraph_text\"].to_list()\\n            labels = [0] * len(test_texts)\\n            ids = test[\"ID\"].tolist()\\n\\n            infer_dataset = BertDataset(test_texts, labels, apply_preprocess=False, tokenizer=tokenizer)\\n            infer_dataset.set_loaders(batch_size=max(1, int(args.batch_size)), split_ratio=1.0)\\n            test_loader, _ = infer_dataset.get_loaders()\\n\\n            all_probs = []\\n            model.eval()\\n            for batch in test_loader:\\n                input_ids, attn_mask, lbls = [t.to(device) for t in batch]\\n                with torch.no_grad():\\n                    outputs = model(input_ids, attention_mask=attn_mask)\\n                    logits = (outputs[\\'logits\\'] if isinstance(outputs, dict) else outputs.logits)\\n                    probs = torch.softmax(logits, dim=-1)[:, 1]\\n                    all_probs.extend(probs.cpu().numpy())\\n\\n            assert len(ids) == len(all_probs), f\"Mismatch: {len(ids)} IDs vs {len(all_probs)} predictions\"\\n            submission = pd.DataFrame({\\n                \"ID\": ids,\\n                \"generated\": all_probs\\n            })\\n            submission.to_csv(\"submission.csv\", index=False)\\n    except Exception as _e:\\n        # Fail-safe: ignore inference errors to not block training result emission\\n        pass\\n\\n    # --- (3) 모델 저장 ---\\n    saved = _save_model_generic(model, model_path)\\n\\n    # --- (4) 결과 dict 구성 ---\\n    used_params = {\\n        \"epochs\": int(args.epochs),\\n        \"batch_size\": int(args.batch_size),\\n        \"train_path\": args.train_path,\\n        \"test_path\": args.test_path,\\n        \"model_name\": \"klue/roberta-base\",\\n        \"lr\": 5e-5,\\n        \"warmup_steps\": 0\\n    }\\n    val_metric = last_val_accuracy\\n    result = {\\n        \"model_pt_path\": saved,\\n        \"validation\": float(val_metric),\\n        \"params\": used_params\\n    }\\n\\n    _save_json_line({\"autofinetuner_result\": result, \"elapsed_sec\": time.time() - t0})\\n    with open(save_dir / \"save_dir.json\", \"w\", encoding=\"utf-8\") as f:\\n        json.dump(result, f, ensure_ascii=False, indent=2)\\n\\n    return result\\n\\nif __name__ == \"__main__\":\\n    try:\\n        _ = autofinetuner_result()\\n    except SystemExit as _e:\\n        if _e.code != 0:\\n            raise',\n",
       " 'log_content': \"ion 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n2025-08-20 15:57:31.944362: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\\nSome weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\\nREADY\\n\",\n",
       " 'result': {'ok': True,\n",
       "  'run_id': '20250820155727',\n",
       "  'returncode': 0,\n",
       "  'run_dir': 'outputs/20250820155727',\n",
       "  'log_path': 'outputs/20250820155727/run.log',\n",
       "  'cmd': ['/home/jeongyuseong/anaconda3/bin/conda',\n",
       "   'run',\n",
       "   '--no-capture-output',\n",
       "   '-n',\n",
       "   'AItxt',\n",
       "   'python',\n",
       "   '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py',\n",
       "   '--healthcheck'],\n",
       "  'error': None},\n",
       " 'exc_args': {'pyfile': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py',\n",
       "  'conda_env': 'AItxt',\n",
       "  'args': ['--healthcheck'],\n",
       "  'timeout': 300,\n",
       "  'raise_on_error': False},\n",
       " 'count': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repaired = repair_code(\n",
    "    source_code_content=source_file_contents,\n",
    "    refactored_code_str=refactored_code,\n",
    "    pyfile=str(proj_paths.refactored),\n",
    "    conda_env_name=conda_env_name\n",
    ") \n",
    "repaired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af1dc833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================makeParamList============================================\n",
      "```json\n",
      "{\n",
      "    \"param_info\": {\n",
      "        \"epochs\": {\n",
      "            \"is_tuned\": false,\n",
      "            \"best_param\": 1,\n",
      "            \"cur_count\": 0,\n",
      "            \"limit_count\": 5\n",
      "        },\n",
      "        \"batch_size\": {\n",
      "            \"is_tuned\": false,\n",
      "            \"best_param\": 1,\n",
      "            \"cur_count\": 0,\n",
      "            \"limit_count\": 5\n",
      "        },\n",
      "        \"train_path\": {\n",
      "            \"is_tuned\": false,\n",
      "            \"best_param\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv\",\n",
      "            \"cur_count\": 0,\n",
      "            \"limit_count\": 5\n",
      "        }\n",
      "    },\n",
      "    \"time_limit\": 3600,\n",
      "    \"cur_exec_time\": 0\n",
      "}\n",
      "```\n",
      "메타데이터 저장경로 :  /home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/metadata.json\n",
      "{'time_limit': 3600, 'cur_exec_time': 0, 'param_info': {'epochs': {'is_tuned': False, 'best_param': 1, 'cur_count': 0, 'limit_count': 5}, 'batch_size': {'is_tuned': False, 'best_param': 1, 'cur_count': 0, 'limit_count': 5}, 'train_path': {'is_tuned': False, 'best_param': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', 'cur_count': 0, 'limit_count': 5}}}\n",
      "==========================================check_metadata============================================\n",
      "모든 조건 만족 -> paramSelect\n",
      "\n",
      "===== Step 1 =====\n",
      "==========================================paramSelect============================================\n",
      "[planner] 대규모(10~20만) 데이터로 이틀 내 완료를 위해 처리량을 늘리되, 무리한 VRAM 사용을 피하려 초기값 1에서 보수적으로 4로 증량. 학습 속도와 안정성의 균형을 노림.\n",
      "args :  ['--epochs=1', '--batch_size=4', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "exec_result 함수 실행 시도.\n",
      "run_kwargs :  {'pyfile': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', 'args': ['--epochs=1', '--batch_size=4', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'timeout': 3600, 'log_dir': PosixPath('/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'), 'raise_on_error': False, 'conda_env': 'AItxt'}\n",
      "실행 명령어 상태 :  ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=4', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "{'ok': True, 'run_id': '20250820155811', 'returncode': 0, 'run_dir': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820155811', 'log_path': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820155811/run.log', 'cmd': ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=4', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'error': None}\n",
      "# CMD: /home/jeongyuseong/anaconda3/bin/conda run --no-capture-output -n AItxt python '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py' --epochs=1 --batch_size=4 '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv' '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'\n",
      "# CWD: /home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/AutoHPO\n",
      "# LAUNCHER: conda_env=AItxt, conda_exec=/home/jeongyuseong/anaconda3/bin/conda\n",
      "# CURRENT_PYEXEC: /home/jeongyuseong/anaconda3/envs/AutoFineTuner/bin/python\n",
      "\n",
      "2025-08-20 15:58:15.129700: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-20 15:58:15.164181: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "2025-08-20 15:58:15.944387: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch: 100%|██████████| 1/1 [00:15<00:00, 15.08s/it]\n",
      "Epoch: 100%|██████████| 1/1 [00:15<00:00, 15.08s/it]\n",
      "{\"autofinetuner_result\": {\"model_pt_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/model.pt\", \"validation\": 0.8571428571428571, \"params\": {\"epochs\": 1, \"batch_size\": 4, \"train_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv\", \"test_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/test.csv\", \"model_name\": \"klue/roberta-base\", \"lr\": 5e-05, \"warmup_steps\": 0}}, \"elapsed_sec\": 56.11780142784119}\n",
      "\n",
      "==========================================saveResult============================================\n",
      "==========================================evaluatate============================================\n",
      "[evaluatate] target_param/validation 누락 → paramSelect\n",
      "\n",
      "===== Step 2 =====\n",
      "==========================================paramSelect============================================\n",
      "[planner] 이틀 내 완료를 위해 처리량을 높이되 메모리 안전을 고려해 1→4로 소폭 상향. 10~20만 문장에서도 OOM 위험을 낮추며 학습 속도 개선을 기대.\n",
      "args :  ['--epochs=1', '--batch_size=4', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "exec_result 함수 실행 시도.\n",
      "run_kwargs :  {'pyfile': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', 'args': ['--epochs=1', '--batch_size=4', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'timeout': 3600, 'log_dir': PosixPath('/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'), 'raise_on_error': False, 'conda_env': 'AItxt'}\n",
      "실행 명령어 상태 :  ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=4', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "{'ok': True, 'run_id': '20250820155942', 'returncode': 0, 'run_dir': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820155942', 'log_path': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820155942/run.log', 'cmd': ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=4', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'error': None}\n",
      "# CMD: /home/jeongyuseong/anaconda3/bin/conda run --no-capture-output -n AItxt python '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py' --epochs=1 --batch_size=4 '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv' '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'\n",
      "# CWD: /home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/AutoHPO\n",
      "# LAUNCHER: conda_env=AItxt, conda_exec=/home/jeongyuseong/anaconda3/bin/conda\n",
      "# CURRENT_PYEXEC: /home/jeongyuseong/anaconda3/envs/AutoFineTuner/bin/python\n",
      "\n",
      "2025-08-20 15:59:46.283859: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-20 15:59:46.318978: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "2025-08-20 15:59:47.093989: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch: 100%|██████████| 1/1 [00:13<00:00, 13.83s/it]\n",
      "Epoch: 100%|██████████| 1/1 [00:13<00:00, 13.83s/it]\n",
      "{\"autofinetuner_result\": {\"model_pt_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/model.pt\", \"validation\": 0.8611111111111112, \"params\": {\"epochs\": 1, \"batch_size\": 4, \"train_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv\", \"test_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/test.csv\", \"model_name\": \"klue/roberta-base\", \"lr\": 5e-05, \"warmup_steps\": 0}}, \"elapsed_sec\": 55.79258346557617}\n",
      "\n",
      "==========================================saveResult============================================\n",
      "==========================================evaluatate============================================\n",
      "[evaluatate] target_param/validation 누락 → paramSelect\n",
      "\n",
      "===== Step 3 =====\n",
      "==========================================paramSelect============================================\n",
      "[planner] 히스토리가 없으므로 metadata의 best_param(1 epoch)으로 베이스라인 확보. 대규모(10~20만)에서도 2일 내 완료를 우선하고, 이후 결과로 batch_size·epochs를 보수적으로 조정.\n",
      "args :  ['--epochs=1', '--batch_size=1', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "exec_result 함수 실행 시도.\n",
      "run_kwargs :  {'pyfile': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', 'args': ['--epochs=1', '--batch_size=1', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'timeout': 3600, 'log_dir': PosixPath('/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'), 'raise_on_error': False, 'conda_env': 'AItxt'}\n",
      "실행 명령어 상태 :  ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=1', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "{'ok': True, 'run_id': '20250820160138', 'returncode': 0, 'run_dir': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820160138', 'log_path': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820160138/run.log', 'cmd': ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=1', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'error': None}\n",
      "# CMD: /home/jeongyuseong/anaconda3/bin/conda run --no-capture-output -n AItxt python '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py' --epochs=1 --batch_size=1 '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv' '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'\n",
      "# CWD: /home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/AutoHPO\n",
      "# LAUNCHER: conda_env=AItxt, conda_exec=/home/jeongyuseong/anaconda3/bin/conda\n",
      "# CURRENT_PYEXEC: /home/jeongyuseong/anaconda3/envs/AutoFineTuner/bin/python\n",
      "\n",
      "2025-08-20 16:01:42.497157: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-20 16:01:42.533591: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "2025-08-20 16:01:43.321887: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch: 100%|██████████| 1/1 [00:27<00:00, 27.45s/it]\n",
      "Epoch: 100%|██████████| 1/1 [00:27<00:00, 27.45s/it]\n",
      "{\"autofinetuner_result\": {\"model_pt_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/model.pt\", \"validation\": 0.9354838709677419, \"params\": {\"epochs\": 1, \"batch_size\": 1, \"train_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv\", \"test_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/test.csv\", \"model_name\": \"klue/roberta-base\", \"lr\": 5e-05, \"warmup_steps\": 0}}, \"elapsed_sec\": 72.93178200721741}\n",
      "\n",
      "==========================================saveResult============================================\n",
      "==========================================evaluatate============================================\n",
      "[evaluatate] target_param/validation 누락 → paramSelect\n",
      "\n",
      "===== Step 4 =====\n",
      "==========================================paramSelect============================================\n",
      "[planner] 히스토리가 없으므로 metadata의 best_param(1)로 베이스라인 설정. max_len=512와 대규모 데이터에서 OOM·불안정을 피하고, 1 epoch 기준 이틀 내 완료 가능성부터 안전하게 검증.\n",
      "args :  ['--epochs=1', '--batch_size=1', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "exec_result 함수 실행 시도.\n",
      "run_kwargs :  {'pyfile': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', 'args': ['--epochs=1', '--batch_size=1', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'timeout': 3600, 'log_dir': PosixPath('/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'), 'raise_on_error': False, 'conda_env': 'AItxt'}\n",
      "실행 명령어 상태 :  ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=1', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "{'ok': True, 'run_id': '20250820160327', 'returncode': 0, 'run_dir': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820160327', 'log_path': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820160327/run.log', 'cmd': ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=1', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'error': None}\n",
      "# CMD: /home/jeongyuseong/anaconda3/bin/conda run --no-capture-output -n AItxt python '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py' --epochs=1 --batch_size=1 '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv' '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'\n",
      "# CWD: /home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/AutoHPO\n",
      "# LAUNCHER: conda_env=AItxt, conda_exec=/home/jeongyuseong/anaconda3/bin/conda\n",
      "# CURRENT_PYEXEC: /home/jeongyuseong/anaconda3/envs/AutoFineTuner/bin/python\n",
      "\n",
      "2025-08-20 16:03:30.887346: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-20 16:03:30.922294: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "2025-08-20 16:03:31.689510: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch: 100%|██████████| 1/1 [00:27<00:00, 27.62s/it]\n",
      "Epoch: 100%|██████████| 1/1 [00:27<00:00, 27.62s/it]\n",
      "{\"autofinetuner_result\": {\"model_pt_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/model.pt\", \"validation\": 0.90625, \"params\": {\"epochs\": 1, \"batch_size\": 1, \"train_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv\", \"test_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/test.csv\", \"model_name\": \"klue/roberta-base\", \"lr\": 5e-05, \"warmup_steps\": 0}}, \"elapsed_sec\": 73.1552381515503}\n",
      "\n",
      "==========================================saveResult============================================\n",
      "==========================================evaluatate============================================\n",
      "[evaluatate] target_param/validation 누락 → paramSelect\n",
      "\n",
      "===== Step 5 =====\n",
      "==========================================paramSelect============================================\n",
      "[planner] 이전 4 제안은 검증 부재. 512 토큰·대규모(10~20만)에서 OOM 위험을 줄이기 위해 1→2로 보수 증량. 처리량을 높여 2일 내 완료 가능성을 키우되 안정성 확보.\n",
      "args :  ['--epochs=1', '--batch_size=2', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "exec_result 함수 실행 시도.\n",
      "run_kwargs :  {'pyfile': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', 'args': ['--epochs=1', '--batch_size=2', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'timeout': 3600, 'log_dir': PosixPath('/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'), 'raise_on_error': False, 'conda_env': 'AItxt'}\n",
      "실행 명령어 상태 :  ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=2', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "{'ok': True, 'run_id': '20250820160514', 'returncode': 0, 'run_dir': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820160514', 'log_path': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820160514/run.log', 'cmd': ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=2', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'error': None}\n",
      "# CMD: /home/jeongyuseong/anaconda3/bin/conda run --no-capture-output -n AItxt python '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py' --epochs=1 --batch_size=2 '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv' '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'\n",
      "# CWD: /home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/AutoHPO\n",
      "# LAUNCHER: conda_env=AItxt, conda_exec=/home/jeongyuseong/anaconda3/bin/conda\n",
      "# CURRENT_PYEXEC: /home/jeongyuseong/anaconda3/envs/AutoFineTuner/bin/python\n",
      "\n",
      "2025-08-20 16:05:18.301868: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-20 16:05:18.336725: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "2025-08-20 16:05:19.114710: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch: 100%|██████████| 1/1 [00:24<00:00, 24.41s/it]\n",
      "Epoch: 100%|██████████| 1/1 [00:24<00:00, 24.41s/it]\n",
      "{\"autofinetuner_result\": {\"model_pt_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/model.pt\", \"validation\": 1.0, \"params\": {\"epochs\": 1, \"batch_size\": 2, \"train_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv\", \"test_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/test.csv\", \"model_name\": \"klue/roberta-base\", \"lr\": 5e-05, \"warmup_steps\": 0}}, \"elapsed_sec\": 68.85248589515686}\n",
      "\n",
      "==========================================saveResult============================================\n",
      "==========================================evaluatate============================================\n",
      "[evaluatate] target_param/validation 누락 → paramSelect\n",
      "\n",
      "===== Step 6 =====\n",
      "==========================================paramSelect============================================\n",
      "[planner] 검증 수치 부재로 급격 증량은 위험. 10~20만 문장·512토큰 조건에서 2일 내 완료를 위해 처리량을 2→3으로 보수 상향, OOM 리스크를 크게 늘리지 않으면서 속도 개선을 노림.\n",
      "args :  ['--epochs=1', '--batch_size=3', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "exec_result 함수 실행 시도.\n",
      "run_kwargs :  {'pyfile': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', 'args': ['--epochs=1', '--batch_size=3', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'timeout': 3600, 'log_dir': PosixPath('/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'), 'raise_on_error': False, 'conda_env': 'AItxt'}\n",
      "실행 명령어 상태 :  ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=3', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "{'ok': True, 'run_id': '20250820160713', 'returncode': 0, 'run_dir': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820160713', 'log_path': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820160713/run.log', 'cmd': ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=3', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'error': None}\n",
      "# CMD: /home/jeongyuseong/anaconda3/bin/conda run --no-capture-output -n AItxt python '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py' --epochs=1 --batch_size=3 '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv' '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'\n",
      "# CWD: /home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/AutoHPO\n",
      "# LAUNCHER: conda_env=AItxt, conda_exec=/home/jeongyuseong/anaconda3/bin/conda\n",
      "# CURRENT_PYEXEC: /home/jeongyuseong/anaconda3/envs/AutoFineTuner/bin/python\n",
      "\n",
      "2025-08-20 16:07:17.631533: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-20 16:07:17.666066: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "2025-08-20 16:07:18.458622: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch: 100%|██████████| 1/1 [00:18<00:00, 18.83s/it]\n",
      "Epoch: 100%|██████████| 1/1 [00:18<00:00, 18.83s/it]\n",
      "{\"autofinetuner_result\": {\"model_pt_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/model.pt\", \"validation\": 0.9333333333333332, \"params\": {\"epochs\": 1, \"batch_size\": 3, \"train_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv\", \"test_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/test.csv\", \"model_name\": \"klue/roberta-base\", \"lr\": 5e-05, \"warmup_steps\": 0}}, \"elapsed_sec\": 60.77318286895752}\n",
      "\n",
      "==========================================saveResult============================================\n",
      "==========================================evaluatate============================================\n",
      "[evaluatate] target_param/validation 누락 → paramSelect\n",
      "\n",
      "===== Step 7 =====\n",
      "==========================================paramSelect============================================\n",
      "[planner] 검증 추세가 없어 epoch은 메타데이터 기준(1) 유지. 2일 내 완료를 위해 처리량을 높이도록 batch_size를 8로 상향해 시간 단축을 우선한다(10~20만 문장 규모 고려).\n",
      "args :  ['--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=./outputs/exp_e1_bs8', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "exec_result 함수 실행 시도.\n",
      "run_kwargs :  {'pyfile': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', 'args': ['--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=./outputs/exp_e1_bs8', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'timeout': 3600, 'log_dir': PosixPath('/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'), 'raise_on_error': False, 'conda_env': 'AItxt'}\n",
      "실행 명령어 상태 :  ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=./outputs/exp_e1_bs8', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "{'ok': True, 'run_id': '20250820160917', 'returncode': 0, 'run_dir': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820160917', 'log_path': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820160917/run.log', 'cmd': ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=./outputs/exp_e1_bs8', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'error': None}\n",
      "# CMD: /home/jeongyuseong/anaconda3/bin/conda run --no-capture-output -n AItxt python '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py' --epochs=1 --batch_size=8 '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv' --save_dir=./outputs/exp_e1_bs8 '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'\n",
      "# CWD: /home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/AutoHPO\n",
      "# LAUNCHER: conda_env=AItxt, conda_exec=/home/jeongyuseong/anaconda3/bin/conda\n",
      "# CURRENT_PYEXEC: /home/jeongyuseong/anaconda3/envs/AutoFineTuner/bin/python\n",
      "\n",
      "2025-08-20 16:09:20.849061: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-20 16:09:20.882462: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "2025-08-20 16:09:21.611095: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch: 100%|██████████| 1/1 [00:12<00:00, 12.99s/it]\n",
      "Epoch: 100%|██████████| 1/1 [00:12<00:00, 12.99s/it]\n",
      "{\"autofinetuner_result\": {\"model_pt_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/model.pt\", \"validation\": 0.96875, \"params\": {\"epochs\": 1, \"batch_size\": 8, \"train_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv\", \"test_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/test.csv\", \"model_name\": \"klue/roberta-base\", \"lr\": 5e-05, \"warmup_steps\": 0}}, \"elapsed_sec\": 50.933738231658936}\n",
      "\n",
      "==========================================saveResult============================================\n",
      "==========================================evaluatate============================================\n",
      "[evaluatate] target_param/validation 누락 → paramSelect\n",
      "\n",
      "===== Step 8 =====\n",
      "==========================================paramSelect============================================\n",
      "[planner] 히스토리 부재이므로 epochs는 메타데이터 기준 1로 베이스라인. 10~20만 문장·max_len=512 환경에서 2일 내 종료를 위해 처리량을 높이되 OOM 위험을 줄여 batch_size=8로 보수 설정, 사전 healthcheck 수행.\n",
      "args :  ['--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--healthcheck', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "exec_result 함수 실행 시도.\n",
      "run_kwargs :  {'pyfile': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', 'args': ['--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--healthcheck', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'timeout': 3600, 'log_dir': PosixPath('/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'), 'raise_on_error': False, 'conda_env': 'AItxt'}\n",
      "실행 명령어 상태 :  ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--healthcheck', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "{'ok': True, 'run_id': '20250820161042', 'returncode': 0, 'run_dir': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820161042', 'log_path': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820161042/run.log', 'cmd': ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--healthcheck', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'error': None}\n",
      "# CMD: /home/jeongyuseong/anaconda3/bin/conda run --no-capture-output -n AItxt python '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py' --epochs=1 --batch_size=8 '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv' --healthcheck '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'\n",
      "# CWD: /home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/AutoHPO\n",
      "# LAUNCHER: conda_env=AItxt, conda_exec=/home/jeongyuseong/anaconda3/bin/conda\n",
      "# CURRENT_PYEXEC: /home/jeongyuseong/anaconda3/envs/AutoFineTuner/bin/python\n",
      "\n",
      "2025-08-20 16:10:46.166572: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-20 16:10:46.199984: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "2025-08-20 16:10:46.924590: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "READY\n",
      "\n",
      "==========================================saveResult============================================\n",
      "==========================================evaluatate============================================\n",
      "[evaluatate] target_param/validation 누락 → paramSelect\n",
      "\n",
      "===== Step 9 =====\n",
      "==========================================paramSelect============================================\n",
      "[planner] 검증 히스토리 부재로 수렴성 판단 불가. 과적합·시간 리스크 최소화 위해 epochs는 메타데이터 값(1) 유지로 베이스라인 확보, 대규모 데이터 처리량 향상을 위해 batch_size=8 적용.\n",
      "args :  ['--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "exec_result 함수 실행 시도.\n",
      "run_kwargs :  {'pyfile': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', 'args': ['--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'timeout': 3600, 'log_dir': PosixPath('/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'), 'raise_on_error': False, 'conda_env': 'AItxt'}\n",
      "실행 명령어 상태 :  ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "{'ok': True, 'run_id': '20250820161136', 'returncode': 0, 'run_dir': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820161136', 'log_path': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820161136/run.log', 'cmd': ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'error': None}\n",
      "# CMD: /home/jeongyuseong/anaconda3/bin/conda run --no-capture-output -n AItxt python '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py' --epochs=1 --batch_size=8 '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv' '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'\n",
      "# CWD: /home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/AutoHPO\n",
      "# LAUNCHER: conda_env=AItxt, conda_exec=/home/jeongyuseong/anaconda3/bin/conda\n",
      "# CURRENT_PYEXEC: /home/jeongyuseong/anaconda3/envs/AutoFineTuner/bin/python\n",
      "\n",
      "2025-08-20 16:11:40.255681: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-20 16:11:40.291763: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "2025-08-20 16:11:41.091027: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch: 100%|██████████| 1/1 [00:21<00:00, 21.70s/it]\n",
      "Epoch: 100%|██████████| 1/1 [00:21<00:00, 21.70s/it]\n",
      "{\"autofinetuner_result\": {\"model_pt_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/model.pt\", \"validation\": 0.975, \"params\": {\"epochs\": 1, \"batch_size\": 8, \"train_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv\", \"test_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/test.csv\", \"model_name\": \"klue/roberta-base\", \"lr\": 5e-05, \"warmup_steps\": 0}}, \"elapsed_sec\": 62.830498933792114}\n",
      "\n",
      "==========================================saveResult============================================\n",
      "==========================================evaluatate============================================\n",
      "[evaluatate] target_param/validation 누락 → paramSelect\n",
      "\n",
      "===== Step 10 =====\n",
      "==========================================paramSelect============================================\n",
      "[planner] 대규모 데이터·히스토리 부재로 우선 데이터 경로를 메타데이터 기준으로 고정하고 healthcheck로 파이프라인 검증. 2일 내 완료를 위해 epochs=1, batch_size=8로 안전하게 시작.\n",
      "args :  ['--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--healthcheck', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "exec_result 함수 실행 시도.\n",
      "run_kwargs :  {'pyfile': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', 'args': ['--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--healthcheck', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'timeout': 3600, 'log_dir': PosixPath('/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'), 'raise_on_error': False, 'conda_env': 'AItxt'}\n",
      "실행 명령어 상태 :  ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--healthcheck', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "{'ok': True, 'run_id': '20250820161331', 'returncode': 0, 'run_dir': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820161331', 'log_path': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820161331/run.log', 'cmd': ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--healthcheck', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'error': None}\n",
      "# CMD: /home/jeongyuseong/anaconda3/bin/conda run --no-capture-output -n AItxt python '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py' --epochs=1 --batch_size=8 '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv' --healthcheck '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'\n",
      "# CWD: /home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/AutoHPO\n",
      "# LAUNCHER: conda_env=AItxt, conda_exec=/home/jeongyuseong/anaconda3/bin/conda\n",
      "# CURRENT_PYEXEC: /home/jeongyuseong/anaconda3/envs/AutoFineTuner/bin/python\n",
      "\n",
      "2025-08-20 16:13:35.045290: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-20 16:13:35.080622: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "2025-08-20 16:13:35.862775: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "READY\n",
      "\n",
      "==========================================saveResult============================================\n",
      "==========================================evaluatate============================================\n",
      "[evaluatate] target_param/validation 누락 → paramSelect\n",
      "\n",
      "===== Step 11 =====\n",
      "==========================================paramSelect============================================\n",
      "[planner] 히스토리·검증치 없음. 대용량(10~20만)과 2일 제한을 고려해 epoch 증가는 위험하므로 우선 데이터 경로를 고정해 재현성 확보, 처리량을 위해 batch_size=8로 보수 설정.\n",
      "args :  ['--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "exec_result 함수 실행 시도.\n",
      "run_kwargs :  {'pyfile': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', 'args': ['--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'timeout': 3600, 'log_dir': PosixPath('/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'), 'raise_on_error': False, 'conda_env': 'AItxt'}\n",
      "실행 명령어 상태 :  ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "{'ok': True, 'run_id': '20250820161420', 'returncode': 0, 'run_dir': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820161420', 'log_path': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820161420/run.log', 'cmd': ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'error': None}\n",
      "# CMD: /home/jeongyuseong/anaconda3/bin/conda run --no-capture-output -n AItxt python '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py' --epochs=1 --batch_size=8 '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv' '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'\n",
      "# CWD: /home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/AutoHPO\n",
      "# LAUNCHER: conda_env=AItxt, conda_exec=/home/jeongyuseong/anaconda3/bin/conda\n",
      "# CURRENT_PYEXEC: /home/jeongyuseong/anaconda3/envs/AutoFineTuner/bin/python\n",
      "\n",
      "2025-08-20 16:14:24.059540: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-20 16:14:24.096061: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "2025-08-20 16:14:24.880500: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch: 100%|██████████| 1/1 [00:16<00:00, 16.56s/it]\n",
      "Epoch: 100%|██████████| 1/1 [00:16<00:00, 16.56s/it]\n",
      "{\"autofinetuner_result\": {\"model_pt_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/model.pt\", \"validation\": 1.0, \"params\": {\"epochs\": 1, \"batch_size\": 8, \"train_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv\", \"test_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/test.csv\", \"model_name\": \"klue/roberta-base\", \"lr\": 5e-05, \"warmup_steps\": 0}}, \"elapsed_sec\": 57.96458601951599}\n",
      "\n",
      "==========================================saveResult============================================\n",
      "==========================================evaluatate============================================\n",
      "[evaluatate] target_param/validation 누락 → paramSelect\n",
      "\n",
      "===== Step 12 =====\n",
      "==========================================paramSelect============================================\n",
      "[planner] 히스토리·검증치 부재로 변화 근거 부족. 2일 제한을 위해 epochs는 메타값 1로 고정하고, 처리량 확보를 위해 batch_size를 12로 보수 상향(512토큰·roberta-base 기준). 경로는 메타 유지.\n",
      "args :  ['--epochs=1', '--batch_size=12', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "exec_result 함수 실행 시도.\n",
      "run_kwargs :  {'pyfile': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', 'args': ['--epochs=1', '--batch_size=12', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'timeout': 3600, 'log_dir': PosixPath('/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'), 'raise_on_error': False, 'conda_env': 'AItxt'}\n",
      "실행 명령어 상태 :  ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=12', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "{'ok': True, 'run_id': '20250820161646', 'returncode': 0, 'run_dir': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820161646', 'log_path': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820161646/run.log', 'cmd': ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=12', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'error': None}\n",
      "# CMD: /home/jeongyuseong/anaconda3/bin/conda run --no-capture-output -n AItxt python '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py' --epochs=1 --batch_size=12 '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv' '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'\n",
      "# CWD: /home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/AutoHPO\n",
      "# LAUNCHER: conda_env=AItxt, conda_exec=/home/jeongyuseong/anaconda3/bin/conda\n",
      "# CURRENT_PYEXEC: /home/jeongyuseong/anaconda3/envs/AutoFineTuner/bin/python\n",
      "\n",
      "2025-08-20 16:16:50.147525: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-20 16:16:50.182124: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "2025-08-20 16:16:51.007495: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch: 100%|██████████| 1/1 [00:15<00:00, 15.68s/it]\n",
      "Epoch: 100%|██████████| 1/1 [00:15<00:00, 15.68s/it]\n",
      "{\"autofinetuner_result\": {\"model_pt_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/model.pt\", \"validation\": 0.9523809523809524, \"params\": {\"epochs\": 1, \"batch_size\": 12, \"train_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv\", \"test_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/test.csv\", \"model_name\": \"klue/roberta-base\", \"lr\": 5e-05, \"warmup_steps\": 0}}, \"elapsed_sec\": 55.93422746658325}\n",
      "\n",
      "==========================================saveResult============================================\n",
      "==========================================evaluatate============================================\n",
      "[evaluatate] target_param/validation 누락 → paramSelect\n",
      "\n",
      "===== Step 13 =====\n",
      "==========================================paramSelect============================================\n",
      "[planner] 히스토리가 없어 경로는 메타데이터로 확정. 이전엔 healthcheck 위주였으므로 이번엔 실제 학습 진행. 10~20만 문장 규모 고려해 epoch=1, batch_size=8로 2일 내 완주를 우선.\n",
      "args :  ['--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "exec_result 함수 실행 시도.\n",
      "run_kwargs :  {'pyfile': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', 'args': ['--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'timeout': 3600, 'log_dir': PosixPath('/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'), 'raise_on_error': False, 'conda_env': 'AItxt'}\n",
      "실행 명령어 상태 :  ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "{'ok': True, 'run_id': '20250820161825', 'returncode': 0, 'run_dir': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820161825', 'log_path': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820161825/run.log', 'cmd': ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'error': None}\n",
      "# CMD: /home/jeongyuseong/anaconda3/bin/conda run --no-capture-output -n AItxt python '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py' --epochs=1 --batch_size=8 '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv' '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'\n",
      "# CWD: /home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/AutoHPO\n",
      "# LAUNCHER: conda_env=AItxt, conda_exec=/home/jeongyuseong/anaconda3/bin/conda\n",
      "# CURRENT_PYEXEC: /home/jeongyuseong/anaconda3/envs/AutoFineTuner/bin/python\n",
      "\n",
      "2025-08-20 16:18:28.987623: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-20 16:18:29.021826: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "2025-08-20 16:18:29.768222: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch: 100%|██████████| 1/1 [00:17<00:00, 17.90s/it]\n",
      "Epoch: 100%|██████████| 1/1 [00:17<00:00, 17.90s/it]\n",
      "{\"autofinetuner_result\": {\"model_pt_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/model.pt\", \"validation\": 0.925, \"params\": {\"epochs\": 1, \"batch_size\": 8, \"train_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv\", \"test_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/test.csv\", \"model_name\": \"klue/roberta-base\", \"lr\": 5e-05, \"warmup_steps\": 0}}, \"elapsed_sec\": 57.83291816711426}\n",
      "\n",
      "==========================================saveResult============================================\n",
      "==========================================evaluatate============================================\n",
      "[evaluatate] target_param/validation 누락 → paramSelect\n",
      "\n",
      "===== Step 14 =====\n",
      "==========================================paramSelect============================================\n",
      "[planner] history 없음 → 경로는 metadata 기준 고정. 10~20만 문장·512 토큰의 메모리/시간 부담을 고려해 epoch=1, batch_size=8로 2일 내 완료 목표. healthcheck는 생략하고 실제 학습 진행.\n",
      "args :  ['--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "exec_result 함수 실행 시도.\n",
      "run_kwargs :  {'pyfile': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', 'args': ['--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'timeout': 3600, 'log_dir': PosixPath('/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'), 'raise_on_error': False, 'conda_env': 'AItxt'}\n",
      "실행 명령어 상태 :  ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "{'ok': True, 'run_id': '20250820162003', 'returncode': 0, 'run_dir': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820162003', 'log_path': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820162003/run.log', 'cmd': ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'error': None}\n",
      "# CMD: /home/jeongyuseong/anaconda3/bin/conda run --no-capture-output -n AItxt python '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py' --epochs=1 --batch_size=8 '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv' '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'\n",
      "# CWD: /home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/AutoHPO\n",
      "# LAUNCHER: conda_env=AItxt, conda_exec=/home/jeongyuseong/anaconda3/bin/conda\n",
      "# CURRENT_PYEXEC: /home/jeongyuseong/anaconda3/envs/AutoFineTuner/bin/python\n",
      "\n",
      "2025-08-20 16:20:07.100389: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-20 16:20:07.134495: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "2025-08-20 16:20:07.919406: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch: 100%|██████████| 1/1 [00:14<00:00, 14.38s/it]\n",
      "Epoch: 100%|██████████| 1/1 [00:14<00:00, 14.38s/it]\n",
      "{\"autofinetuner_result\": {\"model_pt_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/model.pt\", \"validation\": 0.96875, \"params\": {\"epochs\": 1, \"batch_size\": 8, \"train_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv\", \"test_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/test.csv\", \"model_name\": \"klue/roberta-base\", \"lr\": 5e-05, \"warmup_steps\": 0}}, \"elapsed_sec\": 54.632490396499634}\n",
      "\n",
      "==========================================saveResult============================================\n",
      "==========================================evaluatate============================================\n",
      "[evaluatate] target_param/validation 누락 → paramSelect\n",
      "\n",
      "===== Step 15 =====\n",
      "==========================================paramSelect============================================\n",
      "[planner] train_path 히스토리 부재이므로 메타데이터 값으로 고정. 2일 제한 고려해 epoch=1·bs=8로 안전하게 실제 학습 수행, 이전 산출물과 충돌 방지를 위해 save_dir를 분리.\n",
      "args :  ['--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=./outputs/run-trainpath-baseline', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "exec_result 함수 실행 시도.\n",
      "run_kwargs :  {'pyfile': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', 'args': ['--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=./outputs/run-trainpath-baseline', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'timeout': 3600, 'log_dir': PosixPath('/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'), 'raise_on_error': False, 'conda_env': 'AItxt'}\n",
      "실행 명령어 상태 :  ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=./outputs/run-trainpath-baseline', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs']\n",
      "{'ok': True, 'run_id': '20250820162154', 'returncode': 0, 'run_dir': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820162154', 'log_path': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820162154/run.log', 'cmd': ['/home/jeongyuseong/anaconda3/bin/conda', 'run', '--no-capture-output', '-n', 'AItxt', 'python', '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py', '--epochs=1', '--batch_size=8', '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv', '--save_dir=./outputs/run-trainpath-baseline', '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'], 'error': None}\n",
      "# CMD: /home/jeongyuseong/anaconda3/bin/conda run --no-capture-output -n AItxt python '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py' --epochs=1 --batch_size=8 '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv' --save_dir=./outputs/run-trainpath-baseline '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'\n",
      "# CWD: /home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/AutoHPO\n",
      "# LAUNCHER: conda_env=AItxt, conda_exec=/home/jeongyuseong/anaconda3/bin/conda\n",
      "# CURRENT_PYEXEC: /home/jeongyuseong/anaconda3/envs/AutoFineTuner/bin/python\n",
      "\n",
      "2025-08-20 16:21:57.768111: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-20 16:21:57.802205: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "2025-08-20 16:21:58.539217: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch: 100%|██████████| 1/1 [00:17<00:00, 17.93s/it]\n",
      "Epoch: 100%|██████████| 1/1 [00:17<00:00, 17.93s/it]\n",
      "{\"autofinetuner_result\": {\"model_pt_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/model.pt\", \"validation\": 0.875, \"params\": {\"epochs\": 1, \"batch_size\": 8, \"train_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv\", \"test_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/test.csv\", \"model_name\": \"klue/roberta-base\", \"lr\": 5e-05, \"warmup_steps\": 0}}, \"elapsed_sec\": 59.34868860244751}\n",
      "\n",
      "==========================================saveResult============================================\n",
      "==========================================evaluatate============================================\n",
      "[evaluatate] 종료 조건 충족 → END\n",
      "종료 조건 충족 (evaluatate)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'userPrompt': '이틀 내에 작업을 완료하고싶어. 데이터는 참고로 대략 10~20만개의 문장이 준비돼있어.',\n",
       " 'refactoredCode': 'import sys, json, time, pickle\\nfrom pathlib import Path\\n\\ndef _save_model_generic(model, path: Path) -> str:\\n    \"\"\"Try torch save, else pickle; always write to *.pt\"\"\"\\n    path.parent.mkdir(parents=True, exist_ok=True)\\n    try:\\n        import torch  # type: ignore\\n        try:\\n            torch.save(getattr(model, \"state_dict\", lambda: model)(), path)\\n        except Exception:\\n            torch.save(model, path)\\n    except Exception:\\n        with open(path, \"wb\") as f:\\n            pickle.dump(model, f)\\n    return str(path)\\n\\ndef _emit_json_line(payload: dict) -> None:\\n    sys.stdout.write(json.dumps(payload, ensure_ascii=False) + \"\\\\n\")\\n    sys.stdout.flush()\\n\\ndef _save_json_line(payload: dict) -> None:\\n    # Alias to keep compatibility with pseudocode\\n    _emit_json_line(payload)\\n\\ndef autofinetuner_result() -> dict:\\n    \"\"\"\\n    Returns:\\n      {\\n        \"model_pt_path\": str,\\n        \"validation\": float,\\n        \"params\": dict\\n      }\\n    \"\"\"\\n    import argparse\\n    import pandas as pd\\n    import numpy as np\\n    import torch\\n    from transformers import AutoTokenizer, RobertaForSequenceClassification, get_linear_schedule_with_warmup\\n    from torch.optim import AdamW\\n    from tqdm import trange\\n    from dataset import BertDataset, from_csv\\n\\n    t0 = time.time()\\n    parser = argparse.ArgumentParser()\\n    parser.add_argument(\"--epochs\", type=int, default=1)\\n    parser.add_argument(\"--batch_size\", type=int, default=1)\\n    parser.add_argument(\"--save_dir\", type=str, default=\"./outputs\")\\n    parser.add_argument(\"--train_path\", type=str, default=\"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv\")\\n    parser.add_argument(\"--test_path\", type=str, default=\"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/test.csv\")\\n    parser.add_argument(\"--healthcheck\", action=\"store_true\")\\n    args, _ = parser.parse_known_args()\\n\\n    save_dir = Path(args.save_dir); save_dir.mkdir(parents=True, exist_ok=True)\\n    model_path = save_dir / \"model.pt\"\\n\\n    # --- (1) 데이터 로드/전처리/모델 구성 ---\\n    tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-base\")\\n    model = RobertaForSequenceClassification.from_pretrained(\"klue/roberta-base\", num_labels=2)\\n\\n    train_texts, train_labels = from_csv(args.train_path)\\n    dataset = BertDataset(train_texts, train_labels, tokenizer, max_len=512)\\n    dataset.set_loaders(batch_size=max(1, int(args.batch_size)))\\n    train_dataloader, valid_dataloader = dataset.get_loaders()\\n\\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n    model.to(device)\\n\\n    if args.healthcheck:\\n        try:\\n            batch = next(iter(train_dataloader))\\n        except StopIteration:\\n            # 빈 데이터셋이면 임의의 더미 텐서로 forward\\n            batch = (\\n                torch.zeros((1, 4), dtype=torch.long),\\n                torch.ones((1, 4), dtype=torch.long),\\n                torch.zeros((1,), dtype=torch.long),\\n            )\\n        batch = tuple(t.to(device) for t in batch)\\n        b_input_ids, b_input_mask, b_labels = batch\\n        with torch.no_grad():\\n            _ = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\\n        print(\"READY\")\\n        raise SystemExit(0)\\n\\n    # --- Optimizer/Scheduler 구성 (원 코드 유지) ---\\n    param_optimizer = list(model.named_parameters())\\n    no_decay = [\\'bias\\', \\'LayerNorm.weight\\']\\n    optimizer_grouped_parameters = [\\n        {\\'params\\': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\\n         \\'weight_decay_rate\\': 0.1},\\n        {\\'params\\': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\\n         \\'weight_decay_rate\\': 0.0}\\n    ]\\n    optimizer = AdamW(optimizer_grouped_parameters, lr=5e-5, eps=1e-8)\\n    total_steps = max(1, len(train_dataloader) * max(1, int(args.epochs)))\\n    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\\n\\n    # Accuracy 계산 함수 (원 코드 유지)\\n    def flat_accuracy(preds, labels):\\n        pred_flat = np.argmax(preds, axis=1).flatten()\\n        labels_flat = labels.flatten()\\n        return float(np.sum(pred_flat == labels_flat) / len(labels_flat)) if len(labels_flat) > 0 else 0.0\\n\\n    train_loss_set = []\\n    last_val_accuracy = 0.0\\n\\n    # --- (2) 학습 ---\\n    for _ in trange(int(args.epochs), desc=\"Epoch\"):\\n        model.train()\\n        tr_loss = 0.0\\n        nb_tr_steps = 0\\n\\n        for step, batch in enumerate(train_dataloader):\\n            batch = tuple(t.to(device) for t in batch)\\n            b_input_ids, b_input_mask, b_labels = batch\\n            optimizer.zero_grad()\\n            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\\n            loss = outputs[\\'loss\\'] if isinstance(outputs, dict) else outputs.loss\\n            train_loss_set.append(loss.item())\\n            loss.backward()\\n            optimizer.step()\\n            scheduler.step()\\n\\n            tr_loss += loss.item()\\n            nb_tr_steps += 1\\n\\n        # Validation\\n        model.eval()\\n        eval_accuracy = 0.0\\n        nb_eval_steps = 0\\n\\n        for batch in valid_dataloader:\\n            batch = tuple(t.to(device) for t in batch)\\n            b_input_ids, b_input_mask, b_labels = batch\\n            with torch.no_grad():\\n                outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\\n            logits = (outputs[\\'logits\\'] if isinstance(outputs, dict) else outputs.logits).detach().cpu().numpy()\\n            label_ids = b_labels.to(\\'cpu\\').numpy()\\n            tmp_eval_accuracy = flat_accuracy(logits, label_ids)\\n            eval_accuracy += tmp_eval_accuracy\\n            nb_eval_steps += 1\\n\\n        last_val_accuracy = float(eval_accuracy / nb_eval_steps) if nb_eval_steps > 0 else 0.0\\n\\n    # --- 테스트 추론 및 제출 파일 생성 (원 코드 유지) ---\\n    try:\\n        if args.test_path and Path(args.test_path).exists():\\n            test = pd.read_csv(args.test_path)\\n            test_texts = test[\"paragraph_text\"].to_list()\\n            labels = [0] * len(test_texts)\\n            ids = test[\"ID\"].tolist()\\n\\n            infer_dataset = BertDataset(test_texts, labels, apply_preprocess=False, tokenizer=tokenizer)\\n            infer_dataset.set_loaders(batch_size=max(1, int(args.batch_size)), split_ratio=1.0)\\n            test_loader, _ = infer_dataset.get_loaders()\\n\\n            all_probs = []\\n            model.eval()\\n            for batch in test_loader:\\n                input_ids, attn_mask, lbls = [t.to(device) for t in batch]\\n                with torch.no_grad():\\n                    outputs = model(input_ids, attention_mask=attn_mask)\\n                    logits = (outputs[\\'logits\\'] if isinstance(outputs, dict) else outputs.logits)\\n                    probs = torch.softmax(logits, dim=-1)[:, 1]\\n                    all_probs.extend(probs.cpu().numpy())\\n\\n            assert len(ids) == len(all_probs), f\"Mismatch: {len(ids)} IDs vs {len(all_probs)} predictions\"\\n            submission = pd.DataFrame({\\n                \"ID\": ids,\\n                \"generated\": all_probs\\n            })\\n            submission.to_csv(\"submission.csv\", index=False)\\n    except Exception as _e:\\n        # Fail-safe: ignore inference errors to not block training result emission\\n        pass\\n\\n    # --- (3) 모델 저장 ---\\n    saved = _save_model_generic(model, model_path)\\n\\n    # --- (4) 결과 dict 구성 ---\\n    used_params = {\\n        \"epochs\": int(args.epochs),\\n        \"batch_size\": int(args.batch_size),\\n        \"train_path\": args.train_path,\\n        \"test_path\": args.test_path,\\n        \"model_name\": \"klue/roberta-base\",\\n        \"lr\": 5e-5,\\n        \"warmup_steps\": 0\\n    }\\n    val_metric = last_val_accuracy\\n    result = {\\n        \"model_pt_path\": saved,\\n        \"validation\": float(val_metric),\\n        \"params\": used_params\\n    }\\n\\n    _save_json_line({\"autofinetuner_result\": result, \"elapsed_sec\": time.time() - t0})\\n    with open(save_dir / \"save_dir.json\", \"w\", encoding=\"utf-8\") as f:\\n        json.dump(result, f, ensure_ascii=False, indent=2)\\n\\n    return result\\n\\nif __name__ == \"__main__\":\\n    try:\\n        _ = autofinetuner_result()\\n    except SystemExit as _e:\\n        if _e.code != 0:\\n            raise',\n",
       " 'count': 0,\n",
       " 'cur_conda_env': 'AItxt',\n",
       " 'metadata': {'time_limit': 3600,\n",
       "  'cur_exec_time': 0,\n",
       "  'param_info': {'epochs': {'is_tuned': False,\n",
       "    'best_param': 1,\n",
       "    'cur_count': 5,\n",
       "    'limit_count': 5},\n",
       "   'batch_size': {'is_tuned': False,\n",
       "    'best_param': 1,\n",
       "    'cur_count': 5,\n",
       "    'limit_count': 5},\n",
       "   'train_path': {'is_tuned': False,\n",
       "    'best_param': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv',\n",
       "    'cur_count': 5,\n",
       "    'limit_count': 5}}},\n",
       " 'cur_exec_result': {'ok': True,\n",
       "  'run_id': '20250820162154',\n",
       "  'returncode': 0,\n",
       "  'run_dir': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820162154',\n",
       "  'log_path': '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/20250820162154/run.log',\n",
       "  'cmd': ['/home/jeongyuseong/anaconda3/bin/conda',\n",
       "   'run',\n",
       "   '--no-capture-output',\n",
       "   '-n',\n",
       "   'AItxt',\n",
       "   'python',\n",
       "   '/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py',\n",
       "   '--epochs=1',\n",
       "   '--batch_size=8',\n",
       "   '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv',\n",
       "   '--save_dir=./outputs/run-trainpath-baseline',\n",
       "   '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'],\n",
       "  'error': None},\n",
       " 'selectedParamPlan': {'target_param': 'train_path',\n",
       "  'cli_args': ['--epochs=1',\n",
       "   '--batch_size=8',\n",
       "   '--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv',\n",
       "   '--save_dir=./outputs/run-trainpath-baseline',\n",
       "   '--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs'],\n",
       "  'rationale': 'train_path 히스토리 부재이므로 메타데이터 값으로 고정. 2일 제한 고려해 epoch=1·bs=8로 안전하게 실제 학습 수행, 이전 산출물과 충돌 방지를 위해 save_dir를 분리.'},\n",
       " 'log_content': '# CMD: /home/jeongyuseong/anaconda3/bin/conda run --no-capture-output -n AItxt python \\'/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/test_output.py\\' --epochs=1 --batch_size=8 \\'--train_path=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv\\' --save_dir=./outputs/run-trainpath-baseline \\'--save_dir=/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs\\'\\n# CWD: /home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/AutoHPO\\n# LAUNCHER: conda_env=AItxt, conda_exec=/home/jeongyuseong/anaconda3/bin/conda\\n# CURRENT_PYEXEC: /home/jeongyuseong/anaconda3/envs/AutoFineTuner/bin/python\\n\\n2025-08-20 16:21:57.768111: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\\n2025-08-20 16:21:57.802205: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\\nTo enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n/home/jeongyuseong/anaconda3/envs/AItxt/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\\n  warnings.warn(\\n2025-08-20 16:21:58.539217: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\\nSome weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: [\\'classifier.dense.bias\\', \\'classifier.dense.weight\\', \\'classifier.out_proj.bias\\', \\'classifier.out_proj.weight\\']\\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\\n\\nEpoch:   0%|          | 0/1 [00:00<?, ?it/s]\\nEpoch: 100%|██████████| 1/1 [00:17<00:00, 17.93s/it]\\nEpoch: 100%|██████████| 1/1 [00:17<00:00, 17.93s/it]\\n{\"autofinetuner_result\": {\"model_pt_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/outputs/model.pt\", \"validation\": 0.875, \"params\": {\"epochs\": 1, \"batch_size\": 8, \"train_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/train.csv\", \"test_path\": \"/home/jeongyuseong/바탕화면/오픈소스경진대회/AutoFineTuner/datas/test.csv\", \"model_name\": \"klue/roberta-base\", \"lr\": 5e-05, \"warmup_steps\": 0}}, \"elapsed_sec\": 59.34868860244751}\\n',\n",
       " 'lastResult': {'target_param': 'train_path',\n",
       "  'rationale': 'train_path 히스토리 부재이므로 메타데이터 값으로 고정. 2일 제한 고려해 epoch=1·bs=8로 안전하게 실제 학습 수행, 이전 산출물과 충돌 방지를 위해 save_dir를 분리.',\n",
       "  'validation': None,\n",
       "  'params': {},\n",
       "  'model_pt_path': None},\n",
       " 'results': {'20250820155811': {'target_param': 'batch_size',\n",
       "   'rationale': '대규모(10~20만) 데이터로 이틀 내 완료를 위해 처리량을 늘리되, 무리한 VRAM 사용을 피하려 초기값 1에서 보수적으로 4로 증량. 학습 속도와 안정성의 균형을 노림.',\n",
       "   'validation': None,\n",
       "   'params': {},\n",
       "   'model_pt_path': None},\n",
       "  '20250820155942': {'target_param': 'batch_size',\n",
       "   'rationale': '이틀 내 완료를 위해 처리량을 높이되 메모리 안전을 고려해 1→4로 소폭 상향. 10~20만 문장에서도 OOM 위험을 낮추며 학습 속도 개선을 기대.',\n",
       "   'validation': None,\n",
       "   'params': {},\n",
       "   'model_pt_path': None},\n",
       "  '20250820160138': {'target_param': 'epochs',\n",
       "   'rationale': '히스토리가 없으므로 metadata의 best_param(1 epoch)으로 베이스라인 확보. 대규모(10~20만)에서도 2일 내 완료를 우선하고, 이후 결과로 batch_size·epochs를 보수적으로 조정.',\n",
       "   'validation': None,\n",
       "   'params': {},\n",
       "   'model_pt_path': None},\n",
       "  '20250820160327': {'target_param': 'batch_size',\n",
       "   'rationale': '히스토리가 없으므로 metadata의 best_param(1)로 베이스라인 설정. max_len=512와 대규모 데이터에서 OOM·불안정을 피하고, 1 epoch 기준 이틀 내 완료 가능성부터 안전하게 검증.',\n",
       "   'validation': None,\n",
       "   'params': {},\n",
       "   'model_pt_path': None},\n",
       "  '20250820160514': {'target_param': 'batch_size',\n",
       "   'rationale': '이전 4 제안은 검증 부재. 512 토큰·대규모(10~20만)에서 OOM 위험을 줄이기 위해 1→2로 보수 증량. 처리량을 높여 2일 내 완료 가능성을 키우되 안정성 확보.',\n",
       "   'validation': None,\n",
       "   'params': {},\n",
       "   'model_pt_path': None},\n",
       "  '20250820160713': {'target_param': 'batch_size',\n",
       "   'rationale': '검증 수치 부재로 급격 증량은 위험. 10~20만 문장·512토큰 조건에서 2일 내 완료를 위해 처리량을 2→3으로 보수 상향, OOM 리스크를 크게 늘리지 않으면서 속도 개선을 노림.',\n",
       "   'validation': None,\n",
       "   'params': {},\n",
       "   'model_pt_path': None},\n",
       "  '20250820160917': {'target_param': 'epochs',\n",
       "   'rationale': '검증 추세가 없어 epoch은 메타데이터 기준(1) 유지. 2일 내 완료를 위해 처리량을 높이도록 batch_size를 8로 상향해 시간 단축을 우선한다(10~20만 문장 규모 고려).',\n",
       "   'validation': None,\n",
       "   'params': {},\n",
       "   'model_pt_path': None},\n",
       "  '20250820161042': {'target_param': 'epochs',\n",
       "   'rationale': '히스토리 부재이므로 epochs는 메타데이터 기준 1로 베이스라인. 10~20만 문장·max_len=512 환경에서 2일 내 종료를 위해 처리량을 높이되 OOM 위험을 줄여 batch_size=8로 보수 설정, 사전 healthcheck 수행.',\n",
       "   'validation': None,\n",
       "   'params': {},\n",
       "   'model_pt_path': None},\n",
       "  '20250820161136': {'target_param': 'epochs',\n",
       "   'rationale': '검증 히스토리 부재로 수렴성 판단 불가. 과적합·시간 리스크 최소화 위해 epochs는 메타데이터 값(1) 유지로 베이스라인 확보, 대규모 데이터 처리량 향상을 위해 batch_size=8 적용.',\n",
       "   'validation': None,\n",
       "   'params': {},\n",
       "   'model_pt_path': None},\n",
       "  '20250820161331': {'target_param': 'train_path',\n",
       "   'rationale': '대규모 데이터·히스토리 부재로 우선 데이터 경로를 메타데이터 기준으로 고정하고 healthcheck로 파이프라인 검증. 2일 내 완료를 위해 epochs=1, batch_size=8로 안전하게 시작.',\n",
       "   'validation': None,\n",
       "   'params': {},\n",
       "   'model_pt_path': None},\n",
       "  '20250820161420': {'target_param': 'train_path',\n",
       "   'rationale': '히스토리·검증치 없음. 대용량(10~20만)과 2일 제한을 고려해 epoch 증가는 위험하므로 우선 데이터 경로를 고정해 재현성 확보, 처리량을 위해 batch_size=8로 보수 설정.',\n",
       "   'validation': None,\n",
       "   'params': {},\n",
       "   'model_pt_path': None},\n",
       "  '20250820161646': {'target_param': 'epochs',\n",
       "   'rationale': '히스토리·검증치 부재로 변화 근거 부족. 2일 제한을 위해 epochs는 메타값 1로 고정하고, 처리량 확보를 위해 batch_size를 12로 보수 상향(512토큰·roberta-base 기준). 경로는 메타 유지.',\n",
       "   'validation': None,\n",
       "   'params': {},\n",
       "   'model_pt_path': None},\n",
       "  '20250820161825': {'target_param': 'train_path',\n",
       "   'rationale': '히스토리가 없어 경로는 메타데이터로 확정. 이전엔 healthcheck 위주였으므로 이번엔 실제 학습 진행. 10~20만 문장 규모 고려해 epoch=1, batch_size=8로 2일 내 완주를 우선.',\n",
       "   'validation': None,\n",
       "   'params': {},\n",
       "   'model_pt_path': None},\n",
       "  '20250820162003': {'target_param': 'train_path',\n",
       "   'rationale': 'history 없음 → 경로는 metadata 기준 고정. 10~20만 문장·512 토큰의 메모리/시간 부담을 고려해 epoch=1, batch_size=8로 2일 내 완료 목표. healthcheck는 생략하고 실제 학습 진행.',\n",
       "   'validation': None,\n",
       "   'params': {},\n",
       "   'model_pt_path': None},\n",
       "  '20250820162154': {'target_param': 'train_path',\n",
       "   'rationale': 'train_path 히스토리 부재이므로 메타데이터 값으로 고정. 2일 제한 고려해 epoch=1·bs=8로 안전하게 실제 학습 수행, 이전 산출물과 충돌 방지를 위해 save_dir를 분리.',\n",
       "   'validation': None,\n",
       "   'params': {},\n",
       "   'model_pt_path': None}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fineTuned = start_finetuning(\n",
    "    proj_path=proj_paths.proj_root,\n",
    "    save_dir=output_paths.save_root,\n",
    "    target_name=target_name,\n",
    "    refactored_name=refactored_name,\n",
    "    cur_conda_env=conda_env_name,\n",
    "    user_prompt=userPrompt\n",
    ")\n",
    "fineTuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce227b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 코드리펙토링 상태 선언\n",
    "# refactor_state: refactor.CodeRefactorState = {\n",
    "#     \"sourceCode\": source_file_contents,\n",
    "#     \"userPrompt\": userPrompt,\n",
    "# }\n",
    "# refactor_workflow = refactor.getAnalyerWorkflow()\n",
    "# final_state = refactor_workflow.invoke(refactor_state)\n",
    "\n",
    "# # refactored_code 문자열만 추출\n",
    "# refactored_code_str = final_state[\"refactoredCode\"]\n",
    "# codeMaker.write_text_atomic(path_str=str(proj_paths.refactored), content=refactored_code_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b08199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args=[\"--healthcheck\"],\n",
    "# code_args = {\n",
    "#     \"pyfile\": str(proj_paths.refactored),\n",
    "#     \"conda_env\": conda_env_name,\n",
    "#     \"args\" : args,\n",
    "#     \"timeout\": 300,\n",
    "#     \"raise_on_error\": False,\n",
    "# }\n",
    "\n",
    "# ## 코드 리페어 상태정의\n",
    "# codeState: repair.CodeState = {\n",
    "#     \"sourceCode\": source_file_contents,\n",
    "#     \"refactoredCode\": refactored_code_str,\n",
    "#     \"log_content\": \"\",\n",
    "#     \"result\": {},\n",
    "#     \"exc_args\": code_args,\n",
    "#     \"count\": 0,\n",
    "# }\n",
    "\n",
    "# repair_workflow = repair.getCodeRepairWorkflow()\n",
    "# repaired_code = repair_workflow.invoke(codeState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4583e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repaired_code = codeReader.read_text_strict(path_str=str(proj_paths.target))\n",
    "# repaired_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "156deb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 2) 초기 상태 생성\n",
    "# workState: manager.WorkState = {}\n",
    "# workState[\"userPrompt\"] = userPrompt\n",
    "# workState[\"refactoredCode\"] = repaired_code\n",
    "# workState[\"count\"] = 0\n",
    "# workState[\"cur_conda_env\"] = \"AItxt\"\n",
    "\n",
    "# # 3) 실행\n",
    "# final_state = manager.run_finetuning(workState, ftPaths, max_steps=max_steps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoFineTuner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
