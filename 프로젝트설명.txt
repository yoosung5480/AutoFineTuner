## AutoFineTuner 오픈소스 라이브러리 개발 프로젝트.

### 개발배경 : 
인공지능의 시대에서 인공지능의 영역이 아닌것이 있다. 그것은 학습되지 않은 분야에 대한 창의력이다.
인간의 창조성은 이미 있는 해결문제를 통한 결론이 아니라, 새로운 문제를 정의하고, 문제해결법을 제시할수있다.
하지만 우리가 오롯이 고유한 능력을 여감없이 발휘할수 있을까? 우리는 현실적으로 높은 창의력과 그를 뒷받힘할 수행력이 동시에 필요하다.

어떤 모델을 문제과정에 맞춰서 훈련할때, 개발자는 자신의 역량을 발휘해서 특수한 방식의 문제해결방법을 적용할수있다.
하지만 Dacon, Kaggle 또는 여타 산업에서 정확도를 높히는 모델을 만드는것은 자신의 아이디어를 일단 돌아가는 훈련코드를 적용시키는것만으로 끝이 아니다.
보통 그렇게 준비된 단일파일에 대해서, 여러 실험적용을 하면서 에포크 수를 맞춰가고, 또한 하이퍼파라미터를 조절하면서 세부 성능개선이 뒷받혀줘야한다.
이는 보통의 연구자나, AI개발자에게 가장피로하고 자동화가 필요한 부분이다.
파인튜닝과정은 보통 아래와 같이 이뤄진다.
1. 코드리펙토링
2. 훈련파라미터 선정
3. 훈련실행
4. 실행결과 분석 -> 결과보고 2번으로 돌아가기
이런 과정의 일은, 일의 흐름이 명확하며, 판단에 있어서 매우 고도의 지능이 들어가지 않는다. 그렇다면 자동화가 가능하지 않을까?
AutoFineTuner는 위 워크플로우를 완벽히 자동화했다. 코드의 생성부터, 실행결과를 참고할 metadata과 결과파일 실행을 위한 코드리펙토링부터, 업데이트까지 모든걸 자동화한다.

### 개발목표:
AutoFineTuner은 인간 고유의 문제 정의능력과, 해결방안 창조의 영역에는 들어가지 않는다.
사람의 아이디어, "예를들어서 ai개발자가 예를들어 어떤 텍스트 분류작업모델 훈련에 있어서, ko-roberta모델로, 내가 새로만든 데이터셋에 적용하면 그대로 끝나겠는데?" 
라는 생각이 들면, 그 생각을 즉시 수행해주는 AI 파인튜닝만을 위한 특수 워크플로우 AI-agent를 생성하고자 한다.
현재는 실행이 보장되는 target.py 파일에 대해서 코드 리펙토링, 파라미터튜닝을 완벽히 자동화해주는 AI-agent로 시작을했다.
추후에는 AI가 훈련데이터셋의 상황을 읽고, 스스로 target.py까지 사람의 프롬프트를 참고해 생성하는 AI-agent를 만들것이다.



## 프로젝트구조
ROOT_proj/
    - AutoFineTuner/ 
        - workflows/
            - codeRepair/       
                - repair.py         # llm 기반 답변은 일관적이지 못하다. refactor.py를 거친 코드가 정상작동을 보장하기 위해서 반드시 거쳐야하는 워크플로우다.
            - finetuningManager 
                - tuning_manager.py # refactor->repair 를 거쳐서, 의도대로 리펙토링된 코드로 파인튜닝을 시작한다. llm이 파인튜닝 파라미터를 정하고, 파인튜닝 방향도 정한다. (endcondition과 프롬프트와 코드 강건성 알고리즘에 대한 지속적인 업데이트 필요하다.)
                - # 업데이트 예정    # tuning_manager는 가장 복잡한 워크플로우다. 세부기능으로 나눠서, 또다시 모듈화를할 예정이다. 
            - codeRefactor      
                - refactor.py       # 원본 코드를 리펙토링해서, 필수 파라미터를 외부에서 argument화하고, 모델 결과를 result.json으로 변환해서 반환하게 강제하는 코드를 생성한다.
            - codeAnalyzer      
                - analyzer.py       # output.py와, param.txt를 통해서 최적의 모델 훈련을 위한 에포크와 하이퍼파라미터 튜닝을 시키는 코드이다.
        - tool/
            - codeMaker.py          # llm의 답변을 통해서 생선된 텍스트를 파이썬이나, 배시스크립트로 만들어야한다.
            - codeReader.py         # 파이썬파일이나, 배시파일을 읽어들어와야한다. llm이 파일을 잘 이해할수있도로 파싱해야한다.
            - codeLauncher.py       # 원하는 파일명을 지정시, 파일을 실행하게한다. conda 가상환경을 읽어들여서 실행하는 핵심 함수정의
            - file_tools.py         # 파일 읽고쓰는 단순 툴들을 정의해놓을 파일이다. (추후 codeMaker, codeReader, codeLauncher, save_remove 등 들을 모두 합쳐서 통합할려고한다.)
            - json_tools.py         # json형식의 파일을 읽고 쓰는 형식이다. 우리 라이브러리의 metadata와 result의 형식에 맞는 read, write를 지원하고자 한다. 일단은 단순 입출력있다.
            - llms.py               # llm들을 정의한 리스트이다. 이를 통해서 api-key와 클라이언트 호출등을 이 파일에 모두 맡기자 했으나, 개발중에는 ai client는 한곳에 모으지 못햇다. (추후 업데이트)
            - paths.py              # 라이브러리 전체에서 사용하는 핵심경로들을 담을 컨테이너 클래쓰와 그 헬퍼함수를 정의해놨다.
            - save_remove.py        # 파일을 프로세스상 안전하게 제거해주는 함수다.
        - engine/
            - engine.py             # 기본적인 사용 api들과, 챗형식의 인터페이스가 구현된 코드다. 기능에 초점을 맞추느라, gpt코드로 간략히 마무리했다. 추후 업데이트할것이다.
        - interface/                
            # 추후 업데이트 예정.
        - __init__.py
    # - cookbook.ipynb # (원래는 작동됨)
    # 라이브러리 생성물.
    - output.py         # llm이 리펙토링 완료한 실행가능 python파일이다.
    - outputs/  # 사용자가 지정하지 않으면 기본결과 저장 디렉토리로 지정된다.
        - model.pt      # 가장 높은 성능의 훈련점수를 갖는 모델이다.
        - result.json   # 가장최근의 단일 실행파일에 대한 정보가 저장돼있다.
        - results.json  # 모든 실행파일에 대한 정보가 저장돼있다.
        - metadata.json # 실험에 대한 정보가 저장돼있다. best파라미터의 정보와 그 선정과정이 저장돼있다.
        - 202508102256/ # 실행시간이 실행 id가 된다/
            - 202508102256.log
        - 202508102266/
            - 202508102266.log
        - 202508102286/
            - 202508102286.log
    # 사용자편의
    - cookbook/
        - cookbook.ipynb       # 사용자가 사용할수있게, 함수 api 활용예제 코드를 제공해놓음.
    - scripts/          # 사전정의된 배시스크립트로, 단순 배시파일 수정, 실행만으로도 라입브러리 실행가능
        - finetune.sh   # 리펙토링이 끝났고, result.json을 지정한대로 반환해주는 훈련코드에 대해서 적용한다. 자동으로 파인튜닝을 해준다.
        - pipeline.sh   # 리펙토링부터, 파이프라인까지 모두 한번에 실행한다.
        - refactor.sh   # 코드 리펙토링 부분만 먼저수행한다.



